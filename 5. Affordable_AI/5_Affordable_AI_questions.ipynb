{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s8_CApQzghF"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1xbq3-XLmREiBnZBQEweB7HCcW8OgstZu?usp=sharing)\n",
    "\n",
    "# **SAAI** Overview | Background\n",
    "\n",
    "The Summer School on Affordable AI **SAAI** is a project of the AGYA working group Innovation in close collaboration with the AGYA working group Health and Society. [The Arab-German Young Academy of Sciences and Humanities (AGYA)](https://agya.info/) is funded by the  [German Federal Ministry of Education and Research (BMBF)](https://www.bmbf.de/bmbf/en/home/home_node.html) and various Arab and German cooperation partners.\n",
    "<img src=\"https://imgur.com/hMpk6HK.png\" width=\"800\">\n",
    "\n",
    "\n",
    "This particular use'case was developed by Albarqouni Lab at the University of Bonn with our Lebanese partners, namely Dr. Nada El Darra from the Beirut Arab University (BAU). This use-csse was part of a funded project by the Arab German Young Academy (AGYA) and the German Academic Exchange Service (DAAD).\n",
    "\n",
    "Please treat the data and the excercise as strictly confidential data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZzIfAkxCBGV"
   },
   "source": [
    "# Affordable AI  *(~ 90 min)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vp2dJ0YRLj1h"
   },
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTC9JBZCLiBB"
   },
   "source": [
    "Welcome to the AffordableAI notebook, an interactive and educational exploration of affordable artificial intelligence. This exercise is designed to provide hands-on experience in working with a real-world dataset about pomogranate fruits (`'raw_dataset.xlsl'`). Throughout the challenges, you'll have the opportunity to manipulate features, apply various machine learning techniques, and gain practical insights into the application of AI concepts.\n",
    "\n",
    "### Dataset Overview\n",
    "\n",
    "The provided dataset (`'pomegranate_cleaned.csv'`) is a curated collection of statistics extracted from images and their corresponding features. Your journey in the AffordableAI notebook involves leveraging this dataset to address a series of challenges that cover key aspects of data exploration, feature manipulation, and application of machine learning models.\n",
    "\n",
    "![img](https://github.com/albarqounilab/EEDA-Autumn-School/raw/main/images/i93Jbhz.png)\n",
    "\n",
    "The cleaned and complete provided dataset, consists of 564 entries and 25 columns. Each entry corresponds to a sample, and the columns represent different features and attributes associated with pomegranates. Here's a detailed description of the features:\n",
    "\n",
    "- **no.:** A numerical identifier for each entry.\n",
    "  \n",
    "- **receiving_date:** The date when the pomegranates were received.\n",
    "\n",
    "- **location:** The location where the pomegranates were harvested.\n",
    "\n",
    "- **harvesting_date:** The date when the pomegranates were harvested.\n",
    "\n",
    "- **mass_g:** The mass of the pomegranates in grams.\n",
    "\n",
    "- **volume_ml:** The volume of the pomegranate juice in milliliters.\n",
    "\n",
    "- **yield_of_juice_ml:** The yield of juice obtained from the pomegranates.\n",
    "\n",
    "- **length:** The length of the pomegranates.\n",
    "\n",
    "- **width:** The width of the pomegranates.\n",
    "\n",
    "- **location_ElJahliye, location_Hasbaya, location_Rachiine:** Boolean flags indicating the location of ElJahliye, Hasbaya, and Rachiine, respectively.\n",
    "\n",
    "- **day_time_diff:** The time difference associated with the harvesting process.\n",
    "\n",
    "- **n_days:** The number of days from receiving to harvesting.\n",
    "\n",
    "- **humidity:** The humidity level during the harvesting process.\n",
    "\n",
    "- **solar_radiation:** The amount of solar radiation during harvesting.\n",
    "\n",
    "- **air_temperature:** The air temperature during harvesting.\n",
    "\n",
    "Consider as target labels:\n",
    "\n",
    "- **polyphenols_content_mg:** The content of polyphenols in milligrams.\n",
    "\n",
    "- **polyphenols_concentration_mggae/ml:** The concentration of polyphenols per milliliter.\n",
    "\n",
    "- **degree_brix:** The degree Brix, a measure of sugar content.\n",
    "\n",
    "- **ta_av:** Is the average measure associated with acidity.\n",
    "\n",
    "- **maturity:** Boolean indicating the maturity of the pomegranates.\n",
    "\n",
    "- **mi:** MI is a parameter associated with ripening (mature index).\n",
    "\n",
    "- **Cluster:** An integer representing the cluster to which the entry belongs.\n",
    "\n",
    "- **polyphenols_category:** A categorical variable representing the category of polyphenols.\n",
    "\n",
    "The dataset contains a mix of numerical, boolean, and categorical features, providing a comprehensive set of attributes associated with pomegranates. These features will be explored and utilized in the subsequent challenges to gain insights and build predictive models.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "The notebook is structured into sub-challenges, each focusing on a specific aspect of AI exploration and implementation. Here's a brief overview:\n",
    "\n",
    "1. **Preprocessing and Extraction (Sub-challenge 1):**\n",
    "   - Objective: Preoprocess and choose interesting features from the dataset for further analysis.\n",
    "   - Actions: Load the dataset, display initial information, curate and select relevant features for exploration.\n",
    "\n",
    "2. **Feature Exploration and Dimensionality Reduction Visualization (Sub-challenge 2):**\n",
    "   - Objective: Explore selected features, perform dimensionality reduction using PCA, and visualize the data.\n",
    "   - Actions: Explore K-Means, visualize feature distributions, apply PCA for dimensionality reduction, and visualize reduced-dimensional data.\n",
    "\n",
    "3. **Regression and Classification (Sub-challenge 3):**\n",
    "   - Objective: Implement linear regression, logistic regression, and MLP for continuous and categorical variables.\n",
    "   - Actions: Split the data, apply regression models for continuous variables, and classification models for categorical variables.\n",
    "\n",
    "To facilitate your journey in the third sub-challenge, a training file (`'pomegranate_complete_cleaned.csv'`) containing the dataset is provided. This resource is your key to hands-on learning, enabling you to apply AI concepts to real-world scenarios.\n",
    "\n",
    "Get ready to dive into the world of affordable AI, where you'll not only gain practical skills but also uncover the potential of applying artificial intelligence in a cost-effective manner. Happy exploring!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d8rGv85Tvgy"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAHgX79zBLvW",
    "outputId": "ebcea01f-1238-4392-e701-a0e0c745ee51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "curl: (35) schannel: next InitializeSecurityContext failed: Unknown error (0x80092012) - The revocation function was unable to check revocation for the certificate.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "curl: (35) schannel: next InitializeSecurityContext failed: Unknown error (0x80092012) - The revocation function was unable to check revocation for the certificate.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "curl: (35) schannel: next InitializeSecurityContext failed: Unknown error (0x80092012) - The revocation function was unable to check revocation for the certificate.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "curl: (35) schannel: next InitializeSecurityContext failed: Unknown error (0x80092012) - The revocation function was unable to check revocation for the certificate.\n"
     ]
    }
   ],
   "source": [
    "!curl -O -L https://github.com/albarqounilab/EEDA-Autumn-School/raw/main/5.%20Affordable_AI/raw_dataset.xlsx\n",
    "!curl -O -L https://github.com/albarqounilab/EEDA-Autumn-School/raw/main/5.%20Affordable_AI/pomegranate_cleaned.csv\n",
    "!curl -O -L https://github.com/albarqounilab/EEDA-Autumn-School/raw/main/5.%20Affordable_AI/pomegranate_complete_cleaned.csv\n",
    "!curl -O -L https://github.com/albarqounilab/SAAI-Summer-School/raw/main/5.%20Affordable_AI/updated_outlier_pomegranate_complete_cleaned.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMu0FaMIBWKE"
   },
   "source": [
    "## Sub-challenge 1 : Preprocessing and extraction (Choose interesting features)  *~ 30 min*\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to preprocess and extract relevant information from the provided dataset, '`raw_dataset.csv`'. This involves handling missing values, selectively removing unnecessary columns, and transforming specific columns for better analysis.\n",
    "\n",
    "**Here you will:**\n",
    "\n",
    "- **Clean Dataset from Missing Values:**\n",
    "  - Identify and assess the presence of missing values in the dataset.\n",
    "  - Implement appropriate strategies to handle missing values, such as replacement or removal.\n",
    "  - Verify the dataset after handling missing values to ensure data integrity.\n",
    "  - Use `dropna(axis=1, how='all')` to remove columns with all NaN values.\n",
    "\n",
    "- **Selectively Remove Unnecessary Columns:**\n",
    "  - Use the `df.drop(columns)` method to remove specified columns from the DataFrame.\n",
    "  - Reset the index of the DataFrame using `df.reset_index(drop=True)` to maintain a clean index structure.\n",
    "\n",
    "- **Handle Maturity Column:**\n",
    "  - Utilize the code `df['Maturity'] = df['Maturity'] == 'mature'` to transform the 'Maturity' column.\n",
    "  - Verify changes in the DataFrame to ensure the 'Maturity' column reflects the desired True/False values.\n",
    "\n",
    "- **Extract information from unstructured data:**\n",
    "  - Extract width and length values using regular expressions, crucial for information extraction from strings.\n",
    "  - Unifty dates format and extract additional features.\n",
    "\n",
    "By completing these tasks, you will prepare the dataset for further exploration and analysis in AffordableAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "fML-Nr60ZeY7",
    "outputId": "c340a01f-9a78-4d7c-d508-3b4ade1e14a8"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-678a1d05008f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# read excel file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m             ext = inspect_excel_format(\n\u001b[1;32m-> 1058\u001b[1;33m                 \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m             )\n\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(path, content, storage_options)\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontent\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mcontent_or_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     with get_handle(\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Load the dataset from an Excel file\n",
    "file_path = ''  # Replace with your actual file path of the 'raw_dataset'\n",
    "\n",
    "# read excel file\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1Z1onuxiD1k"
   },
   "source": [
    "Use `df.head()` and `df.info()` to understand the structure of the DataFrame. Identify the columns with `df.columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "tXsZ2naZiDSL",
    "outputId": "05b606c8-6449-4630-d452-2a41d1b0a83c"
   },
   "outputs": [],
   "source": [
    "#ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FP_uSmJiTnX",
    "outputId": "fa057743-efc3-413e-c481-15592e7b65bc"
   },
   "outputs": [],
   "source": [
    "#ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mh4UHUppiVrh",
    "outputId": "283b5d7b-130d-45d4-bd7d-cf55d35a554b"
   },
   "outputs": [],
   "source": [
    "#ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlMiRBWgfN5g"
   },
   "source": [
    "### Exercise 1: Clean dataset from missing values\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to clean the dataset by handling missing values. This step is crucial in preparing data for analysis or machine learning models.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "- Identify and assess the presence of missing values in the dataset.\n",
    "- Implement appropriate strategies to handle missing values, such as replacement or removal.\n",
    "- Verify the dataset after handling missing values to ensure data integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQ6m5qrYfW_Y"
   },
   "source": [
    "**Your Task**: Check missing values\n",
    "> **Actions:**\n",
    "1. Count the number of values with `df.isnull().sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2q9c1iNbn7i",
    "outputId": "a338a3b0-6dcd-4c93-842a-e060eb63fd27"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "#ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFTYyqD6dd0J"
   },
   "source": [
    "**Your Task**: Drop all the missing rows in `No. ` and remove empty columns\n",
    "\n",
    "> **Actions:**\n",
    "1. Use the `df.dropna(subset=['No. '])` from [docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)\n",
    "2. Remember to reset the index once you update your dataframe `df.reset_index(drop=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "MFgSuf9bhE32",
    "outputId": "99201207-ca82-44ee-85c4-02c6919c1497"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "# ToDo: your code goes here\n",
    "# Reset index after dropping rows\n",
    "# ToDo: your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUk11mJvB3_N"
   },
   "source": [
    "**Your Task: Selectively Remove Unnecessary Columns**\n",
    "\n",
    "In this task, your objective is to selectively remove columns that are deemed unnecessary for further analysis. Specifically, you are instructed to remove the following columns: `'No. ', 'Humidity data', 'Temperature', 'Digital camera', 'Degree Brix'`.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "1. Use the `df.drop(columns)` method to remove the specified columns from the DataFrame ([docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)).\n",
    "2. Reset the index of the DataFrame using `df.reset_index(drop=True)` to maintain a clean index structure.\n",
    "\n",
    "By completing this task, you will streamline the dataset, retaining only the relevant columns for subsequent analysis and ensuring a more focused exploration in AffordableAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "nrDun1lWmhtA",
    "outputId": "44f6cf8c-46e8-4ce0-a534-79a72d8a3742"
   },
   "outputs": [],
   "source": [
    "columns_to_remove =  # Replace with the actual column names\n",
    "\n",
    "# Remove the specified columns\n",
    "# ToDo: your code goes here\n",
    "# Drop rows where the 'column_name' has NaN values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lv9NaNdeJtzn",
    "outputId": "6acaba4e-078b-4a14-d8e0-beb703cfe4a4"
   },
   "outputs": [],
   "source": [
    "# Check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ljvvUZyKiiL"
   },
   "source": [
    "**Your Task: Handle Maturity Column**\n",
    "\n",
    "By examining the value counts using `df['Maturity'].value_counts()`, it appears that there are some values present. Your objective is to fill the '`Maturity`' column with `True` where 'mature' exists and `False` otherwise.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "1. Utilize the code `df['Maturity'] = df['Maturity'] == 'mature'` to transform the 'Maturity' column.\n",
    "2. Verify the changes in the DataFrame to ensure the 'Maturity' column reflects the desired True/False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pFlBn9xKwuT",
    "outputId": "214fb8dd-4f44-49ad-be08-30562fc8850e"
   },
   "outputs": [],
   "source": [
    "# Maturity value count\n",
    "# ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFP7S-rnK_cf"
   },
   "source": [
    "Lets fill the column with True in case mature exist and False otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "sDgZYSdwKhNt",
    "outputId": "dce26e85-9ca1-4ec1-9908-24d20ae6c933"
   },
   "outputs": [],
   "source": [
    "# ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z4LT2zXLL-r"
   },
   "source": [
    "We can drop all the NaN such as `'Unnamed: 3'\tUnnamed: 4'` (verify the number automatically assigned to the column) `'color intensity'`\n",
    "with `df.dropna(axis=1, how='all')`:\n",
    "\n",
    "> - `axis=1`: columns\n",
    "- `axis=0`: rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZOiaTxNB3_N"
   },
   "outputs": [],
   "source": [
    "# ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlU2m4YUig6p"
   },
   "source": [
    "What is the new shape of the cleaned DataFrame for rows and columns?\n",
    ">`df.shape`. You may have noticed this can also be seen at the bottom of the DataFrame `print(df)` or `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRt-lVURil3R",
    "outputId": "4291d7c4-b13b-4d43-d3dd-a8661936dae9"
   },
   "outputs": [],
   "source": [
    "# ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-usIMSSn828"
   },
   "source": [
    "### Exercise 2: Extract Length and Width Using Regular Expressions\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to extract width and length values from a specific column in a Pandas DataFrame using regular expressions. This skill is essential when dealing with unstructured data that requires pattern matching for information extraction.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "1. **Define Regex Patterns:**\n",
    "   - `length_pattern = r'length\\D*([\\d.]+)'`: Regex pattern for extracting 'Length' values. It looks for the word \"length\" followed by optional non-digit characters `(\\D*)` and captures one or more digits or dots `(([\\d.]+))`.\n",
    "   - `width_pattern = r'width\\D*([\\d.]+)'`: Regex pattern for extracting 'Width' values. Similar to the 'Length' pattern, it looks for the word \"width\" followed by optional non-digit characters and captures one or more digits or dots.\n",
    "\n",
    "2. **Extract and Clean 'Length' Values:**\n",
    "   - `df['Length'] = df['Dimensions (mm)'].str.extract(length_pattern, flags=re.IGNORECASE)`: Use `str.extract` to apply the 'Length' regex pattern to the 'Dimensions (mm)' column and extract matched values into a new 'Length' column.\n",
    "   - `df['Length'] = pd.to_numeric(df['Length'], errors='coerce')`: Clean up 'Length' values by converting them to numeric format and handling errors.\n",
    "\n",
    "3. **Extract and Clean 'Width' Values:**\n",
    "   - `df['Width'] = df['Unnamed: 11'].str.extract(width_pattern, flags=re.IGNORECASE)`: Use `str.extract` to apply the 'Width' regex pattern to the 'Unnamed: 11' column and extract matched values into a new 'Width' column.\n",
    "   - `df['Width'] = pd.to_numeric(df['Width'], errors='coerce')`: Clean up 'Width' values by converting them to numeric format and handling errors.\n",
    "\n",
    "4. **Drop Original Columns:**\n",
    "   - `df = df.drop(['Dimensions (mm)', 'Unnamed: 11'], axis=1)`: Drop the original 'Dimensions (mm)' and 'Unnamed: 11' columns from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd_DTgS2WSYv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define a regex pattern for extracting length\n",
    "length_pattern = # ToDo: your code goes here\n",
    "\n",
    "# Extract 'Length' values using str.extract\n",
    "df['Length'] = # ToDo: your code goes here\n",
    "\n",
    "# Clean up 'Length' values (remove non-numeric characters)\n",
    "df['Length'] = # ToDo: your code goes here\n",
    "\n",
    "# Define a regex pattern for extracting width\n",
    "width_pattern = # ToDo: your code goes here\n",
    "\n",
    "# Extract 'Width' values using str.extract\n",
    "df['Width'] = # ToDo: your code goes here\n",
    "\n",
    "# Clean up 'Width' values (remove non-numeric characters)\n",
    "df['Width'] = # ToDo: your code goes here\n",
    "\n",
    "# Drop the original 'Dimensions (mm)' and 'Unnamed: 9' columns\n",
    "df = # ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "1i3GTJzud2d6",
    "outputId": "9cd45751-ff6c-493c-c6bc-20e494968aa3"
   },
   "outputs": [],
   "source": [
    "# Now, df contains the fixed and renamed columns\n",
    "df[['Length','Width']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POVqxrwogMN1"
   },
   "source": [
    "### Exercise 3: Fix Noise and Blank Spaces in Column Names\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to clean and standardize column names by removing noise, extra spaces, and ensuring a consistent lowercase format. This step is crucial for maintaining data integrity and facilitating ease of use in subsequent analyses.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "Use a loop to iterate over all columns `[col.strip() for col in df.columns]`\n",
    "\n",
    "\n",
    "1. Use the `str.strip()` function to remove leading and trailing spaces from column names.\n",
    "2. Utilize `str.lower()` to convert column names to lowercase for consistency.\n",
    "3. Apply `str.replace()` to eliminate any noise or unwanted characters in column names. i.e. `str.replace(' ', '_'), str.replace('(', ''), str.replace(')', ''), str.replace('__', '_'), str.replace('_____', '_')`\n",
    "\n",
    "These actions, when applied to `df.columns`, will result in cleaner, standardized column names, enhancing the overall data quality. Remember to adjust the functions as needed based on the specific noise or issues present in your dataset.\n",
    "\n",
    "See [docs](https://docs.python.org/3/library/stdtypes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQiAtN6vWr6U"
   },
   "outputs": [],
   "source": [
    "# Fixing column names\n",
    "\n",
    "# Apply str.strip()\n",
    "df.columns = #ToDo: your code goes here\n",
    "\n",
    "# Apply str.lower()\n",
    "df.columns = #ToDo: your code goes here\n",
    "\n",
    "# Apply str.replace() for specific character removal and space replacement\n",
    "df.columns = #ToDo: your code goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57cDyi-XK743",
    "outputId": "79bae812-e5e1-471d-c7d1-407fb69cf8fc"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6I4UcQQhWrg"
   },
   "source": [
    "### Exercise 4: Encode the Location as a Numeric Value\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to encode location information as numeric values in a Pandas DataFrame. This encoding is essential for certain machine learning algorithms that require numerical input.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "1. **Show Value Counts and Histogram:**\n",
    "   - Display the value counts using `df['location'].value_counts()`.\n",
    "   - Plot a histogram for the 'location' column using `df['location'].hist()`.\n",
    "\n",
    "2. **Fix Blank Spaces and Remove Blanks:**\n",
    "   - Replace blank spaces in the 'Hasbaya' category with a corrected label.\n",
    "   - Remove blank spaces from all location values using `df.location = df.location.str.replace(' ', '')`.\n",
    "\n",
    "3. **One-Hot Encoding:**\n",
    "   - Utilize one-hot encoding for the 'location' column.\n",
    "   - Concatenate the one-hot encoded columns with the original DataFrame.\n",
    "   - `pd.concat([df, pd.get_dummies(df['location'], prefix='location')], axis=1)`\n",
    "\n",
    "Show the `value_counts()` and `hist()` for the location column.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gw4Xz-P9kI5y",
    "outputId": "5cf953b5-bb30-429e-f70b-89ccd8b88cc8"
   },
   "outputs": [],
   "source": [
    "#ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "zESzoluYkYms",
    "outputId": "80c4e91a-c616-4d4b-e85b-49c4f3e0e380"
   },
   "outputs": [],
   "source": [
    "#ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NKD-E4_B3_O"
   },
   "source": [
    "Fix the Hasbaya blank space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsU8tgyjkdMD"
   },
   "source": [
    "Choose an appropriate encoding method for the location column. This could involve using techniques like [label encoding](https://www.geeksforgeeks.org/ml-label-encoding-of-datasets-in-python/) or [one-hot encoding](https://www.geeksforgeeks.org/ml-one-hot-encoding-of-datasets-in-python/), depending on the nature of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSvNjM4JXWsc"
   },
   "outputs": [],
   "source": [
    "# Remove blank spaces from location values\n",
    "df.location = #ToDo: your code goes here\n",
    "\n",
    "# One-hot encoding 'location' column\n",
    "df = pd.concat([df, pd.get_dummies()]) #ToDo: your code goes here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHQFUaDgk4bE",
    "outputId": "ecfa2670-718c-474f-8c86-10c851a523c4"
   },
   "outputs": [],
   "source": [
    "# Display the DataFrame with fixed columns and one-hot encoding\n",
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlSe1HG2fpVC"
   },
   "source": [
    "### Exercise 4: Extract and Manipulate Date Information\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Inconsistent date formats can hinder operations like calculating day differences or mapping continuous values. By ensuring a uniform date format, we enable accurate analysis, making it easier to perform tasks such as computing time differences and extracting meaningful insights from the data. This process involves formatting dates, calculating day differences, and mapping continuous values for an improved analysis.\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to extract and manipulate date information from the `'harvesting_date'` and `'receiving_date'` columns in a Pandas DataFrame. This process involves formatting dates to a consistent format.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "1. **Inspection:**\n",
    "   - Inspect the date formats in `df['harvesting_date'].values` and `'receiving_date'`. In ocations, individual values are easilly spoted, and you can change a particular entry with `formatted_dates[i] = '04/09/2023'` with `i` being the index you want to change.\n",
    "\n",
    "2. **Format Dates:**\n",
    "   - Use the `format_date` function in `'harvesting_date'` and `'receiving_date'` to standardize them to `'%d/%m/%Y'`. Some entries may initially be in the format `'%Y-%d-%m %H:%M:%S'` or `'%Y-%m-%d %H:%M:%S'` (*day `d` and month `m` change positions*).\n",
    "\n",
    "3. **Map a Continuous Value for Day Difference:**\n",
    "   - Extract min and max day values from the 'harvesting_date' column. `df['harvesting_date'].dt.day.min()` and `df['harvesting_date'].dt.day.max()` will do the trick.\n",
    "   - Map day values to a continuous range between 0.0 and 1.0, storing the result in a new column `'day_time_diff'`. `df['harvesting_date'].apply(lambda x: (x.day - min_day) / (max_day - min_day))`\n",
    "\n",
    "\n",
    "4. **Calculate Number of Days Since Harvesting:**\n",
    "   - Calculate the difference in days and store it in a new column 'n_days'. Use simple substraction between the two date type formats: `(df['receiving_date'] - df['harvesting_date']).dt.days`\n",
    "\n",
    "5. **Reset Index:**\n",
    "   - Reset the DataFrame index to enhance data structure. `df = df.reset_index(drop=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koLlGlAWXsx2"
   },
   "source": [
    "Inspect the date formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6Io-qd0Xqwh"
   },
   "outputs": [],
   "source": [
    "#ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cX8cXtLsX-J-"
   },
   "source": [
    "Use the format dates function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24y-Ou7xvklj",
    "outputId": "0b0ca868-3814-4802-ce44-43792ed761e3"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Function to format the date in both directions\n",
    "def format_date(value, from_format, to_format):\n",
    "    if isinstance(value, datetime):\n",
    "        # If the value is already a datetime object, format it accordingly\n",
    "        return value.strftime(to_format)\n",
    "    try:\n",
    "        # Attempt to parse the date using the specified format\n",
    "        date_obj = datetime.strptime(value, from_format)\n",
    "        return date_obj.strftime(to_format)\n",
    "    except ValueError:\n",
    "        # If parsing fails, return the original value\n",
    "        return value\n",
    "\n",
    "# Apply the function to the 'harvesting_date' column and create a new list\n",
    "fornat_a = '' #ToDo: your code goes here\n",
    "fornat_b = '' #ToDo: your code goes here\n",
    "fornat_c = '' #ToDo: your code goes here\n",
    "formatted_dates = [format_date(date, fornat_a, fornat_c) if not isinstance(date, datetime) else format_date(date, fornat_b, fornat_c) for date in df['harvesting_date'].values]\n",
    "formatted_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXkNrCiwXJkC"
   },
   "source": [
    "You need to replace the third item which appear as a typing error `'4/92023',`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlt5vZrdD3iK",
    "outputId": "7c6026d7-ad0f-40d7-a673-92cd50b50656"
   },
   "outputs": [],
   "source": [
    "formatted_dates[2] =  #ToDo: your code goes here\n",
    "\n",
    "# Conversion to datetime format\n",
    "df['harvesting_date'] = formatted_dates\n",
    "df['harvesting_date'] = pd.to_datetime(df['harvesting_date'], format='%d/%m/%Y')\n",
    "\n",
    "df['receiving_date'] = pd.to_datetime(df['receiving_date'], format='%d/%m/%Y')\n",
    "print(df['harvesting_date'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e03D7frfvrL2"
   },
   "source": [
    "And also map a continuous value for the day difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdoQCV8OYwqG"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Extract min and max day values\n",
    "min_day = #ToDo: your code goes here\n",
    "max_day = #ToDo: your code goes here\n",
    "\n",
    "# Map it to a value between 0.0 and 1.0\n",
    "df['day_time_diff'] = df['harvesting_date'].apply(lambda x: (x.day - min_day) / (max_day - min_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJbgDgGAvvLN",
    "outputId": "215465e5-ae99-4042-c5ba-61e7990f636b"
   },
   "outputs": [],
   "source": [
    "#ToDo: your code goes here\n",
    "df[['harvesting_date', 'day_time_diff']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeRj24iSvyDk"
   },
   "source": [
    "It may be useful to know the number of days since harvesting. Lets add it to our feature columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oH986YJFZFTa"
   },
   "outputs": [],
   "source": [
    "# Calculate the difference in days and store it in a new column 'n_days'\n",
    "df['n_days'] = #ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcotnZ-BZK2P"
   },
   "source": [
    "let's see the value count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G49VTWdBvxrj",
    "outputId": "3f3b6e3d-6aaa-4e4c-b174-dc2d6aa3a29f"
   },
   "outputs": [],
   "source": [
    "#ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh55rBNuZXGD"
   },
   "source": [
    "now reset the dataset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "9IQrqn7XB3_S",
    "outputId": "49ca0220-06c5-4b37-d427-9efea9d8e713"
   },
   "outputs": [],
   "source": [
    "#ToDo: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "am3gsXEOUTrr"
   },
   "source": [
    "### Exercise 5: Discretize Output\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to discretize the 'polyphenols_content_mg' variable into categories and visualize the distribution of polyphenols content in the dataset.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "1. **Display Descriptive Statistics:**\n",
    "   - Print descriptive statistics for the 'polyphenols_content_mg' variable using `df['polyphenols_content_mg'].describe()`.\n",
    "\n",
    "2. **Create Histogram:**\n",
    "   - Generate a histogram to visualize the distribution of polyphenols content.\n",
    "   - Use `plt.hist()` with specified bins and formatting options.\n",
    "\n",
    "3. **Discretize Polyphenols Content:**\n",
    "   - Create a new column '`polyphenols_category`' with discrete labels based on polyphenols content.\n",
    "   - Utilize `pd.cut()` to discretize 'polyphenols_content_mg' into categories ('low', 'moderate', 'high') with specified bins.\n",
    "   - After inspecting the histogram and value count, find experimental values that you consider can explain the categories better.\n",
    "\n",
    "4. **Visualize Discretized Categories:**\n",
    "   - Plot a histogram to visualize the distribution of polyphenols content categories using `plt.hist()`.\n",
    "\n",
    "Explore the distribution of polyphenols content and understand how discretizing the variable into categories ('low', 'moderate', 'high') affects the overall distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "WI8umw0uTAzC",
    "outputId": "e658c4ee-2bb4-4515-94fd-f167c1ac6f91"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display descriptive statistics\n",
    "#ToDo: your code goes here\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(df['polyphenols_content_mg'], bins=100, edgecolor='black')\n",
    "plt.title('Distribution of Polyphenols Content')\n",
    "plt.xlabel('Polyphenols Content (mg)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5-zOSKAYvqd"
   },
   "source": [
    "\n",
    "Try different values for the lower and upper threshold, these will be important for the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "5FJpunTCT-kB",
    "outputId": "a7230357-d2db-4afc-e362-713b4186a99e"
   },
   "outputs": [],
   "source": [
    "# Create a new column with discrete labels\n",
    "lower_threshold = '' #ToDo: your code goes here\n",
    "upper_threshold = '' #ToDo: your code goes here\n",
    "labels_ = ['low', 'moderate', 'high']\n",
    "df['polyphenols_category'] = pd.cut(df['polyphenols_content_(mg)'],\n",
    "                                    bins=[-float('inf'), lower_threshold, upper_threshold, float('inf')],\n",
    "                                    labels= labels_,\n",
    "                                    right=False)  # Include the left bin edge, exclude the right bin edge\n",
    "\n",
    "print(df['polyphenols_category'].value_counts())\n",
    "df['polyphenols_category'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QEbv9EqwCzs"
   },
   "source": [
    "As you can see, real-life datasets can be messy. Completing these exercises equips you with essential skills to tackle everyday life datasets effectively.\n",
    "\n",
    "Finally, when you are finished you will want to save the cleaned dataframe in a .csv format\n",
    "- `index=False` helps you load the DataFrame without the previous index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWJvqq6twMLq"
   },
   "outputs": [],
   "source": [
    "df.to_csv('pomegranate_cleaned_.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW2F8fSw0QNC"
   },
   "source": [
    "### Bonus feature extraction *(Do not re-run | Image dataset is not available)*\n",
    "\n",
    "Here we have pre-computed some additional metrics from the pomegranade images, which you can compute yourself with the following scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfiMQOGI0TGK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "\n",
    "def crop_pomegranate(image):\n",
    "    # Get the original image dimensions\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Calculate the new height for cropping\n",
    "    new_height = int(height * 1 / 2.5)\n",
    "    # Calculate the new width for cropping\n",
    "    new_width = int(width * 6 / 9)\n",
    "\n",
    "    # Calculate the amount to remove from each side\n",
    "    remove_from_each_side = (width - new_width) // 2\n",
    "\n",
    "    # Crop the image by removing 2/10 from each side of the width\n",
    "    cropped_image = image[new_height:, remove_from_each_side:(width - remove_from_each_side)]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def resize_image(image, target_height):\n",
    "    # Calculate the aspect ratio of the original image\n",
    "    aspect_ratio = image.shape[1] / image.shape[0]\n",
    "\n",
    "    # Calculate the new width based on the target height and original aspect ratio\n",
    "    new_width = int(target_height * aspect_ratio)\n",
    "\n",
    "    # Resize the image to the calculated width and target height\n",
    "    resized_image = cv2.resize(image, (new_width, target_height))\n",
    "    return resized_image\n",
    "\n",
    "def crop_center(image, target_width, target_height):\n",
    "    # Get the dimensions of the original image\n",
    "    original_height, original_width = image.shape[:2]\n",
    "\n",
    "    # Calculate the center of the image\n",
    "    center_x = original_width // 2\n",
    "    center_y = original_height // 2\n",
    "\n",
    "    # Calculate the crop box coordinates\n",
    "    crop_x1 = max(0, center_x - target_width // 2)\n",
    "    crop_y1 = max(0, center_y - target_height // 2)\n",
    "    crop_x2 = min(original_width, center_x + target_width // 2)\n",
    "    crop_y2 = min(original_height, center_y + target_height // 2)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_image = image[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "# Function to convert RGB image to Lab color space\n",
    "def rgb_to_lab(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "\n",
    "# Specify the target resolution after cropping\n",
    "target_height = 250  # Adjust as needed\n",
    "target_width = 200\n",
    "\n",
    "# Specify the directory containing your images\n",
    "base_directory = \"/home/Images_folder\" # Use the actual path of the images\n",
    "\n",
    "# Get a list of all subdirectories in the base directory\n",
    "subdirectories = [subdir for subdir in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, subdir))]\n",
    "\n",
    "# Create an empty list to store the first image array from each subdirectory\n",
    "side_images = []\n",
    "\n",
    "# Loop through each subdirectory with tqdm for progress tracking\n",
    "for subdir in tqdm(subdirectories, desc=\"Processing Subdirectories\"):\n",
    "    # Get the list of files in the subdirectory\n",
    "    image_files = os.listdir(os.path.join(base_directory, subdir))\n",
    "\n",
    "    # Find the first image file in the subdirectory\n",
    "    for image_file in image_files:\n",
    "        if \"Side 2\" in image_file:\n",
    "          if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "              image_path = os.path.join(base_directory, subdir, image_file)\n",
    "              break\n",
    "\n",
    "\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Crop the image to keep two-thirds of the width and cut one-third of the height\n",
    "    cropped_image = crop_pomegranate(image)\n",
    "\n",
    "    # Resize the cropped image\n",
    "    resized_image = resize_image(cropped_image, target_height)\n",
    "\n",
    "    # Crop center to ensure same array dimensions resolution\n",
    "    cropped_center_image = crop_center(resized_image, target_width, target_height)\n",
    "\n",
    "    # Convert the image to Lab color space\n",
    "    resized_image_lab = rgb_to_lab(cropped_center_image)\n",
    "\n",
    "    # Append the images to the list\n",
    "    side_images.append(resized_image_lab)\n",
    "\n",
    "    print(f\"\\ncropped_image {cropped_image.shape}, resized_image {resized_image.shape}, cropped_center_image {cropped_center_image.shape}, resized_image_lab {resized_image_lab.shape}\")\n",
    "\n",
    "    # Display the original, cropped, and Lab color space images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original Image\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Cropped Image\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(resized_image_lab)\n",
    "    plt.title(\"Lab Color Space\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Convert the list of arrays to a NumPy array\n",
    "side_images = np.array(side_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfL7UhYJ5iHz",
    "outputId": "773f2541-b502-476d-8b5a-5517dee301a7"
   },
   "outputs": [],
   "source": [
    "# @title Compute statistical moments from RGB color space\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import moment\n",
    "\n",
    "def extract_features_from_dataset(image_dataset):\n",
    "    features_list = []\n",
    "\n",
    "    for img_array in image_dataset:\n",
    "        # Calculate mean pixel values for each channel\n",
    "        mean_pixel_values = np.mean(img_array, axis=(0, 1))\n",
    "\n",
    "        # Flatten the image array to calculate statistical moments\n",
    "        flattened_img = img_array.flatten()\n",
    "\n",
    "        # Calculate statistical moments (mean, variance, skewness, kurtosis)\n",
    "        moments = [moment(flattened_img, moment=i) for i in range(1, 5)]\n",
    "\n",
    "        # Calculate median and mode\n",
    "        median_intensity = np.median(flattened_img)\n",
    "        mode_intensity = float(pd.Series(flattened_img).mode().iloc[0])\n",
    "\n",
    "        # Combine features for this image\n",
    "        image_features = mean_pixel_values.tolist() + moments + [median_intensity, mode_intensity]\n",
    "        features_list.append(image_features)\n",
    "\n",
    "    # Create a DataFrame to store the features\n",
    "    column_names = ['mean_R', 'mean_G', 'mean_B', 'mean_intensity', 'variance_intensity', 'skewness_intensity', 'kurtosis_intensity', 'median_intensity', 'mode_intensity']\n",
    "    df = pd.DataFrame(features_list, columns=column_names)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load your dataset\n",
    "#image_dataset = np.load('numpy_array.npy')\n",
    "\n",
    "# Extract features from the dataset\n",
    "df = extract_features_from_dataset(side_images)\n",
    "\n",
    "# Now, you can use the DataFrame for regression or other analysis\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFShdIT85tkJ",
    "outputId": "051f255f-0293-42ac-c0a7-0b4d3734a686"
   },
   "outputs": [],
   "source": [
    "# @title Compute statistical moments from LAB color space\n",
    "def extract_features_from_dataset_lab(image_dataset):\n",
    "    features_list = []\n",
    "\n",
    "    for img_array in image_dataset:\n",
    "        # Calculate mean pixel values for each channel\n",
    "        mean_pixel_values = np.mean(img_array, axis=(0, 1))\n",
    "\n",
    "        # Flatten the image array to calculate statistical moments\n",
    "        flattened_img = img_array.flatten()\n",
    "\n",
    "        # Calculate statistical moments (mean, variance, skewness, kurtosis)\n",
    "        moments = [moment(flattened_img, moment=i) for i in range(1, 5)]\n",
    "\n",
    "        # Calculate median and mode\n",
    "        median_intensity = np.median(flattened_img)\n",
    "        mode_intensity = float(pd.Series(flattened_img).mode().iloc[0])\n",
    "\n",
    "        # Combine features for this image\n",
    "        image_features = mean_pixel_values.tolist() + moments + [median_intensity, mode_intensity]\n",
    "        features_list.append(image_features)\n",
    "\n",
    "    # Create a DataFrame to store the features\n",
    "    column_names = ['mean_a', 'mean_b', 'mean_L', 'mean_intensity_lab', 'variance_intensity_lab', 'skewness_intensity_lab', 'kurtosis_intensity_lab', 'median_intensity_lab', 'mode_intensity_lab']\n",
    "    df = pd.DataFrame(features_list, columns=column_names)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load your dataset\n",
    "#image_dataset = np.load('numpy_array.npy')\n",
    "\n",
    "# Extract features from the dataset\n",
    "df = extract_features_from_dataset_lab(side_images)\n",
    "\n",
    "# Now, you can use the DataFrame for regression or other analysis\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uJKy8_ZWHyY"
   },
   "source": [
    "## Sub-challenge 2 : Feature Exploration and Dimensionality Reduction Visualization (Data exploration)\n",
    "\n",
    "Objective: In this exercise, you will have the opportunity to explore various features within the dataset and apply a dimensionality reduction technique—PCA (Principal Component Analysis). The goal is to visualize the dataset in reduced dimensions and observe potential patterns and clusters.\n",
    "\n",
    "**Here you will apply:**\n",
    "\n",
    "- **Correlation matrix**\n",
    "- **Clustering (K-means) & Dim. Reduction and Visualization (PCA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZzDhvvrBunm"
   },
   "source": [
    "### Load dataset\n",
    "\n",
    "Objective: Load the dataset with the additional features and give it a look to the metrics, data types, missing values and histograms.\n",
    "\n",
    "`df.info(), df.describe(), df.isnull().sum(), df.hist()`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r91FHoWbB6J8",
    "outputId": "234bfba4-df58-4591-ab61-fb9008eb1d61"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('pomegranate_cleaned.csv')  # Replace '_.csv' with the actual file path\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "tXpOCJEpEd3i",
    "outputId": "da849080-1ddc-4145-9780-9c3dd9547678"
   },
   "outputs": [],
   "source": [
    "print(\"Dataset Preview:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "_uaMqb-G7iPg",
    "outputId": "27f3afee-ecc5-44db-fb06-a7d2a6e175aa"
   },
   "outputs": [],
   "source": [
    "print(\"Display descriptive statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aA04Bq-iCspR",
    "outputId": "17905614-6118-4be1-c718-ec067270dddd"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uWHqvncLErno",
    "outputId": "a97169b7-c2c2-467d-c919-7ae2bb732c4c"
   },
   "outputs": [],
   "source": [
    "#@title Visualize distributions of features in the DataFrame\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# Visualize the distributions of features\n",
    "def visualize_distributions(df):\n",
    "    # Plot histograms for each feature\n",
    "    for column in df.columns:\n",
    "        plt.figure(figsize=(12,10))\n",
    "        sns.histplot(df[column], kde=True)\n",
    "        plt.title(f'Distribution of {column}')\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "\n",
    "# Visualize distributions of features in the DataFrame\n",
    "visualize_distributions(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzzYa2hz7_1Z"
   },
   "source": [
    "### Exercise 1: Visualize Correlation Matrix\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to visually explore the correlation between variables in the dataset by creating and visualizing a correlation matrix. Understanding the relationships between variables is crucial for gaining insights into the dataset's structure.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "1. **Create Correlation Matrix:**\n",
    "   - Use the `corr()` method in Pandas to compute the pairwise correlation of columns: `correlation_matrix = df.corr()`. Make sure to remove the feature formats you cannot correlate i.e. `%_date` and discrete `location`.\n",
    "\n",
    "2. **Visualize Correlation Matrix:**\n",
    "   - Utilize a visualization library, such as Seaborn and/or Matplotlib, to create a heatmap of the correlation matrix. `sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={'size': 10})`\n",
    "   To enlarge the confusion matrix you can previously run `plt.figure(figsize=(16, 12))`.\n",
    "   \n",
    "3. **Analyze the Heatmap:**\n",
    "   - Interpret the heatmap to identify patterns and relationships between variables.\n",
    "   - Positive values indicate a positive correlation, while negative values indicate a negative correlation. The intensity of color represents the strength of the correlation.\n",
    "\n",
    "Completing these actions will provide a visual representation of the relationships between variables in the dataset, aiding in the identification of patterns and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "naIS-ajLcA01",
    "outputId": "a474d443-4f8c-4f5e-a78c-74b8808ade18"
   },
   "outputs": [],
   "source": [
    "correlation_matrix = df.drop(columns=['harvesting_date','receiving_date', 'location']).corr()  # Corrected from data.corr() to df.corr()\n",
    "# Enlarge the heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={'size': 10})\n",
    "\n",
    "# Set plot title and show the plot\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExKpcVpt-Dh5"
   },
   "source": [
    "From the correlation matrix try to address the following questions:\n",
    "\n",
    "- Strongest Correlations: Identify the pairs with the strongest positive and negative correlations.\n",
    "\n",
    "- Interpretation of Coefficients: Explain the interpretation of correlation coefficients close to 1, 0, and -1.\n",
    "\n",
    "- Correlation vs. Causation: [Does correlation means causation](https://www.abs.gov.au/statistics/understanding-statistics/statistical-terms-and-concepts/correlation-and-causation#:~:text=A%20correlation%20between%20variables%2C%20however,relationship%20between%20the%20two%20events.)? Can you think of an example?\n",
    "\n",
    "- Feature Selection: Which features do you think will have the highest impact?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKMzUe1khGmF"
   },
   "source": [
    "**Amswer:**\n",
    "\n",
    "- Strongest correlations:\n",
    "\n",
    "  - The strongest positive correlation is between the `mass_g` (mass of pomegranates in grams) and `volume_ml` (volume of pomegranate juice in milliliters) features, with a correlation coefficient of `1.0`. This indicates that the mass of pomegranates is linearly correlated with the volume they have.\n",
    "\n",
    "  - Mass and Yield of Juice: There is a strong positive correlation between the mass (`mass_g`) of pomegranates and the yield of juice (`yield_of_juice`) obtained. This is expected, as larger pomegranates are likely to produce more juice.\n",
    "\n",
    "  - Length and Width: The length and width of the pomegranates (`length` and `width`) also exhibit a strong positive correlation. This indicates that the shape of the pomegranates is relatively consistent, as increases in length tend to be associated with increases in width.\n",
    "\n",
    "  - Location Flags: The location flags (`location_ElJahliye`, `location_Hasbaya`, `location_Rachiine`) show some correlation with other features. For example, `location_ElJahliye` has negative correlations with mass and volume, indicating potential differences in pomegranates from this location.\n",
    "\n",
    "  - Temperature and Solar Radiation: The features related to environmental conditions during harvesting (`humidity`, `solar_radiation`, `air_temperature`) have moderate correlations with other features. These correlations can provide insights into how environmental factors might influence pomegranate characteristics.\n",
    "\n",
    "  - Polyphenols Content and Concentration: The polyphenols-related features (`polyphenols_content_mg`, `polyphenols_concentration_mggae/ml`) show positive correlations with several other features, such as mass, volume, and yield of juice. This suggests a potential relationship between the size of the pomegranates and their polyphenol content.\n",
    "\n",
    "  - Day Time Difference and Number of Days: The features related to time (`day_time_diff`, `n_days`) have relatively weak correlations with other features. However, they may still be valuable in understanding how the duration between receiving and harvesting affects pomegranate characteristics.\n",
    "\n",
    "- Interpretation of Coefficients\n",
    "\n",
    "  - Correlation coefficients close to 1 indicate a strong positive linear relationship between two variables. For example, a correlation coefficient of 1.0 between mass_g and volume_ml means that for every 1 gram increase in pomegranate mass, the volume of juice increases by an average of 1.0 milliliters.\n",
    "\n",
    "  - Correlation coefficients close to 0 indicate no linear relationship between two variables. For example, a correlation coefficient of 0 between `n_days` (number of days from receiving to harvesting) and `maturity` (Boolean indicating the maturity of pomegranates) means that there is no significant relationship between these two factors.\n",
    "\n",
    "  - Correlation coefficients close to `-1` indicate a strong negative linear relationship between two variables. For example, a correlation coefficient of `-0.47` between `location_ElJahliye` and `mass_g` indicates that pomegranates from El Jahliye tend to have smaller mass than the ones from Rachiine.\n",
    "\n",
    "- Correlation vs. Causation\n",
    "\n",
    "  - Correlation does not imply causation. Just because two variables are correlated does not mean that one causes the other. For example, just because the number of ice cream sales is correlated with the number of shark attacks does not mean that ice cream sales cause shark attacks.\n",
    "\n",
    "- Feature Selection\n",
    "\n",
    "  - The features that will have the highest impact on the target labels are those that are most strongly correlated with the target labels. For example, the `mass_g`, `volume_ml`, and `degree_brix` features are all strongly correlated with the `polyphenols_content_mg` target label, so they are likely to be important for predicting polyphenol content.\n",
    "\n",
    "  - However, it is important to note that correlation does not necessarily imply causation, so it is important to be careful when selecting features for a machine learning model. It is also important to consider the specific application of the model, as the important features may vary depending on the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvjjLmawI_zP"
   },
   "source": [
    "### Exercise 2: KMeans Clustering and Visualization\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to apply KMeans clustering to a dataset with relevant features, visualize the resulting clusters in a two-dimensional space, and explore patterns and groupings within the data.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "1. **Feature Exploration:**\n",
    "   - Select a set of features from the dataset that you find interesting or relevant. Features such as `'mass_g', 'volume_ml', 'length', 'width', 'location_ElJahliye', 'location_Hasbaya', 'location_Rachiine', 'n_days', and 'day_time_diff'` may be considered. Avoid using target labels.\n",
    "\n",
    "2. **Evaluate Clustering Quality:**\n",
    "   - Calculate and interpret the inertia, Davies-Bouldin index, and silhouette score to assess the quality of the clustering solution.\n",
    "\n",
    "3. **Standardize the Features:**\n",
    "   - Use `StandardScaler()` to standardize the selected features. Standardization ensures consistent scaling for both visualization and clustering.\n",
    "\n",
    "4. **Apply PCA for Visualization:**\n",
    "   - Utilize PCA to reduce the dimensionality of the standardized features to two components.\n",
    "   - Visualize the dataset in a 2D space.\n",
    "\n",
    "5. **Perform KMeans Clustering:**\n",
    "   - Apply the KMeans clustering algorithm to the reduced-dimensional data.\n",
    "   - Choose an appropriate number of clusters (e.g., `n_clusters=3`).\n",
    "\n",
    "6. **Visualize Clusters:**\n",
    "   - Visualize the clusters in the 2D space obtained from PCA.\n",
    "   - Color each point based on its assigned cluster.\n",
    "\n",
    "Explore different features and visualize their behavior with varying numbers of clusters. Interpret the clustering results to gain insights into the underlying patterns within the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91saEl-puoY3"
   },
   "source": [
    "*Optional:* Lets try to infer a reasonable/optimal number of clusters for our data. Here we will assess the quality of clusters generated by a clustering algorithm using three metrics: [inertia](https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/), [Davies-Bouldin index](https://www.geeksforgeeks.org/davies-bouldin-index/), and [silhouette score](https://www.geeksforgeeks.org/silhouette-algorithm-to-determine-the-optimal-value-of-k/). Remember that these metrics help quantify how well the data is partitioned into distinct groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiuKatX1Mu-0"
   },
   "outputs": [],
   "source": [
    "# Select relevant features for clustering\n",
    "features = ['mass_g', 'length', #'width', ... # In this example, features such 'mass_g' and 'lenght' are used\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "yUyAwJ1kGrTH",
    "outputId": "242dfbe5-b152-4302-e363-d7485391661c"
   },
   "outputs": [],
   "source": [
    "# @title Optimal number of clusters\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "inertia_values = []\n",
    "davies_bouldin_scores = []  # to store Davies-Bouldin scores\n",
    "silhouette_scores = []  # to store Silhouette Scores\n",
    "possible_clusters = range(2, 10)  # Try different numbers of clusters (computation time may vary)\n",
    "\n",
    "for n_clusters in possible_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(df[features])  # fitting the features\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "\n",
    "    # Calculate Davies-Bouldin Index\n",
    "    labels = kmeans.labels_\n",
    "    davies_bouldin = davies_bouldin_score(df[features], labels)\n",
    "    davies_bouldin_scores.append(davies_bouldin)\n",
    "\n",
    "    # Calculate Silhouette Score\n",
    "    silhouette = silhouette_score(df[features], labels)\n",
    "    silhouette_scores.append(silhouette)\n",
    "\n",
    "# Plot the Elbow Method graph\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(possible_clusters, inertia_values, marker='o', linestyle='-', color='b', label='Intertia values')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia (Within-cluster Sum of Squares)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot the Davies-Bouldin Index graph\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(possible_clusters, davies_bouldin_scores, marker='o', linestyle='-', color='r', label='Davies-Bouldin Score')\n",
    "plt.title('Davies-Bouldin Score for Optimal Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Davies-Bouldin Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot the Silhouette Score graph\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(possible_clusters, silhouette_scores, marker='o', linestyle='-', color='g', label='Silhouette Score')\n",
    "plt.title('Silhouette Score for Optimal Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ohFyPe3MwLR"
   },
   "source": [
    "Now its your time to explore different features, and visualize them using the learnred visualization algorthms PCA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "XVgUjU6Y0uA_",
    "outputId": "93c7928a-1fb6-4ab8-d66d-abe08ec56e0d"
   },
   "outputs": [],
   "source": [
    "#@title 2D PCA Visualization | Kmeans clustering | Continuous variable | Discrete variable\n",
    "\n",
    "# @markdown Try to find the best number of clusters or components that explain the data in 2D for continuous and discrete labels.\n",
    "\n",
    "# @markdown **Select the visualization mode:**\n",
    "mode = \"Discrete target\" # @param [\"Clusters\", \"Continuous target\", \"Discrete target\"]\n",
    "\n",
    "# @markdown **Setup:**\n",
    "\n",
    "# @markdown Clusters:\n",
    "n_clusters = 5 # @param {type:\"integer\"}\n",
    "\n",
    "# @markdown PCA components:\n",
    "n_components = 3 # @param {type:\"number\"}\n",
    "\n",
    "# @markdown Annotate Continuous or discrete labels\n",
    "\n",
    "# Continuous labels:\n",
    "continuous_output = \"polyphenols_concentration_mggae/ml\" # @param [\"polyphenols_content_mg\", \"polyphenols_concentration_mggae/ml\", \"degree_brix\", \"ta_av\", \"mi\"]\n",
    "continuous_output = df[continuous_output]\n",
    "\n",
    "# Discrete label:\n",
    "# df['polyphenols_category'] # df['maturity']\n",
    "# Continuous labels:\n",
    "discrete_output = \"polyphenols_category\" # @param [\"polyphenols_category\", \"maturity\"]\n",
    "discrete_output = df[discrete_output]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[features])\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Reduce dimensionality for visualization (using PCA)\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Visualize clusters in 2D with gradient based on polyphenols_content_mg\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "if mode==\"Clusters\":\n",
    "  plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=df['Cluster'], cmap='coolwarm')\n",
    "  # Add legend\n",
    "  for cluster_label in range(n_clusters):\n",
    "        cluster_points = reduced_data[df['Cluster'] == cluster_label]\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {cluster_label}')\n",
    "  plt.legend()\n",
    "elif mode==\"Continuous target\":\n",
    "  scatter = plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=continuous_output, cmap='coolwarm', alpha=0.8)\n",
    "  plt.colorbar(scatter, label=f'{continuous_output.name}')  # Add colorbar with label\n",
    "elif mode==\"Discrete target\":\n",
    "  discrete_labels = pd.Categorical(discrete_output)\n",
    "  scatter = plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=discrete_labels.codes, cmap='coolwarm', alpha=0.8)\n",
    "  for label in discrete_output.unique():\n",
    "        indices = discrete_output[discrete_output == label].index\n",
    "        plt.scatter(reduced_data[indices, 0], reduced_data[indices, 1], label=f'{discrete_output.name}: {label}')\n",
    "  plt.legend()\n",
    "\n",
    "\n",
    "# Customize plot\n",
    "plt.title(f'2D PCA visualizaation with {continuous_output.name}')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "-nNC2A0AFF1I",
    "outputId": "0abd36bc-9d37-43cd-aede-7d3b7e2b6566"
   },
   "outputs": [],
   "source": [
    "# @title 3D visualization Kmeans clustering\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# @markdown Try to find the best number of clusters or components that explain the data in 3D for continuous and discrete labels.\n",
    "\n",
    "# @markdown **Select the visualization mode:**\n",
    "mode = \"Discrete target\" # @param [\"Clusters\", \"Continuous target\", \"Discrete target\"]\n",
    "\n",
    "# @markdown **Setup:**\n",
    "\n",
    "# @markdown Clusters:\n",
    "n_clusters = 3 # @param {type:\"integer\"}\n",
    "\n",
    "# @markdown PCA components:\n",
    "n_components = 0.95 # @param {type:\"number\"}\n",
    "\n",
    "# @markdown Annotate Continuous or discrete labels\n",
    "\n",
    "# Continuous labels:\n",
    "continuous_output = \"polyphenols_content_mg\" # @param [\"polyphenols_content_mg\", \"polyphenols_concentration_mggae/ml\", \"degree_brix\", \"ta_av\", \"mi\"]\n",
    "continuous_output = df[continuous_output]\n",
    "\n",
    "# Discrete label:\n",
    "# df['polyphenols_category'] # df['maturity']\n",
    "# Continuous labels:\n",
    "discrete_output = \"maturity\" # @param [\"polyphenols_category\", \"maturity\"]\n",
    "discrete_output = df[discrete_output]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[features])\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Reduce dimensionality for visualization (using PCA)\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Visualize clusters in 2D with gradient based on polyphenols_content_mg\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[features])\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Reduce dimensionality for visualization (using PCA)\n",
    "pca = PCA(n_components=3)\n",
    "reduced_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Visualize clusters in 3D using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "if mode == \"Clusters\":\n",
    "    for cluster_label in range(3):\n",
    "        cluster_points = reduced_data[df['Cluster'] == cluster_label]\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=cluster_points[:, 0],\n",
    "            y=cluster_points[:, 1],\n",
    "            z=cluster_points[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=4, opacity=0.8),\n",
    "            name=f'Cluster {cluster_label}',\n",
    "            customdata=df[df['Cluster'] == cluster_label]['no.'],\n",
    "            hovertemplate='<b>Cluster</b>: %{text}<br><b>no.</b>: %{customdata}',\n",
    "            text=df[df['Cluster'] == cluster_label]['Cluster']\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "        scene=dict(xaxis_title='PC1', yaxis_title='PC2', zaxis_title='PC3'),\n",
    "        title='KMeans Clustering - 3D'\n",
    "    )\n",
    "\n",
    "elif mode == \"Continuous target\":\n",
    "    scatter = go.Scatter3d(\n",
    "        x=reduced_data[:, 0],\n",
    "        y=reduced_data[:, 1],\n",
    "        z=reduced_data[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=4, opacity=0.8, color=continuous_output, colorscale='agsunset'),\n",
    "        customdata=df['no.'],\n",
    "        hovertemplate='<b>no.</b>: %{customdata}',\n",
    "        text=df['Cluster']\n",
    "    )\n",
    "\n",
    "    # Add gradient colorbar to the trace\n",
    "    scatter.marker.colorbar = dict(title=f'{continuous_output.name}')\n",
    "\n",
    "    fig.add_trace(scatter)\n",
    "    fig.update_layout(scene=dict(xaxis_title='PC1', yaxis_title='PC2', zaxis_title='PC3'),\n",
    "                      title=f'PCA with {continuous_output.name}')\n",
    "\n",
    "elif mode == \"Discrete target\":\n",
    "    discrete_labels = pd.Categorical(discrete_output)\n",
    "    for label in discrete_output.unique():\n",
    "        indices = discrete_output[discrete_output == label].index\n",
    "        cluster_points = reduced_data[indices]\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=cluster_points[:, 0],\n",
    "            y=cluster_points[:, 1],\n",
    "            z=cluster_points[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=4, opacity=0.8),\n",
    "            name=f'{discrete_output.name}: {label}',\n",
    "            customdata=df.loc[indices]['no.'],\n",
    "            hovertemplate='<b>no.</b>: %{customdata}',\n",
    "            text=df.loc[indices]['Cluster']\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "        scene=dict(xaxis_title='PC1', yaxis_title='PC2', zaxis_title='PC3'),\n",
    "        title=f'PCA with {discrete_output.name}'\n",
    "    )\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-hIeFXjeQq8"
   },
   "source": [
    "## Sub-challenge 3: Regression and Classification\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to perform regression and classification tasks using the provided dataset `'pomegranate_complete_cleaned.csv'`. The objective is to implement and evaluate the performance of linear regression, logistic regression, and a Multi-Layer Perceptron (MLP) for both continuous and categorical variables.\n",
    "\n",
    "**Here you will:**\n",
    "\n",
    "- **Select the Features:**\n",
    "  - Choose relevant features from the dataset for regression and classification tasks.\n",
    "\n",
    "- **Regression:**\n",
    "  - Explore linear regression to predict a continuous variable.\n",
    "  - Explore logistic regression to predict categorical variables.\n",
    "\n",
    "- **Multi-Layer Perceptron:**\n",
    "  - **MLP Regression:**\n",
    "    - Implement a Multi-Layer Perceptron Regressor for predicting continuous variables.\n",
    "    - Assess the performance of the MLP Regressor compared with linear regression.\n",
    "\n",
    "  - **MLP Classification:**\n",
    "    - Implement a Multi-Layer Perceptron Classifier for categorical variables.\n",
    "    - Evaluate the model's classification performance compared with logistic regression.\n",
    "\n",
    "Adjust the code as needed based on the specifics of your dataset. Perform a thorough evaluation and analysis of the regression and classification results with the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjC8kDX9sFaB"
   },
   "outputs": [],
   "source": [
    "# @title Import libraries for sub-challenge 3\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report, mean_absolute_error, explained_variance_score, mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD3e7MnUfji6"
   },
   "source": [
    "### Load dataset\n",
    "\n",
    "Load the dataset and inspect column names and data types with `df.info()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOYxlWk7fjjD",
    "outputId": "a027ca2a-52db-4b63-a1b9-13dc5a7f14d6"
   },
   "outputs": [],
   "source": [
    "# # Load the dataset\n",
    "df = pd.read_csv('pomegranate_complete_cleaned.csv')  # Replace '_.csv' with the actual file path\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09GInARgf-3x"
   },
   "source": [
    "### Exercise 1: Regression - Linear and Logistic with Feature Scaling\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to perform regression tasks using the provided dataset 'pomegranate_complete_cleaned.csv'. Specifically, we will implement linear regression for continuous variables and logistic regression for categorical variables while incorporating feature scaling.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "1. **Select the Features:**\n",
    "   - Choose relevant features from the dataset for both linear and logistic regression.\n",
    "\n",
    "2. **Feature Scaling:**\n",
    "   - Utilize feature scaling, such as `StandardScaler()`, to standardize the selected features. This step ensures consistent scaling for both linear and logistic regression.\n",
    "\n",
    "3. **Linear Regression:**\n",
    "   - Implement linear regression to predict a continuous target variable.\n",
    "   - Define a split ratio for the dataset into training and testing sets using `train_test_split`.\n",
    "   - Train the linear regression model on the training set.\n",
    "   - Make predictions on the test set and evaluate the model's performance using appropriate regression metrics (e.g., R2, Mean Squared Error, Mean Absolute Error, Mean-Median Std).\n",
    "\n",
    "4. **Logistic Regression:**\n",
    "   - Select a categorical target variable for logistic regression.\n",
    "   - Make predictions on the test set and evaluate the model's classification performance using appropriate metrics (e.g., accuracy, precision, recall, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJl3CGnxuNqW"
   },
   "outputs": [],
   "source": [
    "features = ['volume_ml', 'mass_g', 'length', 'width',\n",
    "       'location_ElJahliye', 'location_Hasbaya', 'location_Rachiine',\n",
    "       'day_time_diff', 'n_days','humidity', 'solar_radiation',\n",
    "       'air_temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "gvQyvEu0B3_X",
    "outputId": "e238b83e-7a86-4dda-be02-77514731f837"
   },
   "outputs": [],
   "source": [
    "# @title Linear regression\n",
    "# Assuming 'df' is your DataFrame containing the data\n",
    "# and 'polyphenols_content_mg' is the target variable\n",
    "\n",
    "# @markdown **Setup:**\n",
    "X = df[features]\n",
    "# Continuous labels:\n",
    "y = \"polyphenols_content_mg\" # @param [\"polyphenols_content_mg\", \"polyphenols_concentration_mggae/ml\", \"degree_brix\", \"ta_av\", \"mi\"]\n",
    "y = df[y]\n",
    "\n",
    "# @markdown Train-test split:\n",
    "split = 0.2 # @param {type:\"number\"}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=42)\n",
    "\n",
    "# Initialize and train the regression model with scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics on the scaled predictions\n",
    "mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
    "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
    "mae_scaled = mean_absolute_error(y_test, y_pred_scaled)\n",
    "rmse_scaled = np.sqrt(mse_scaled)\n",
    "explained_variance = explained_variance_score(y_test, y_pred_scaled)\n",
    "msle_scaled = mean_squared_log_error(y_test, y_pred_scaled)\n",
    "\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(y_test, y_pred_scaled)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], lw=2, color='red')  # Identity line\n",
    "plt.xlabel(f'Actual {y.name}')\n",
    "plt.ylabel(f'Predicted {y.name}')\n",
    "plt.title('Linear Regression with Scaling - Actual vs. Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Report the results with scaling\n",
    "print(f'Mean Squared Error with Scaling: {mse_scaled}')\n",
    "print(f'Mean Absolute Error with Scaling: {mae_scaled}')\n",
    "print(f'Root Mean Squared Error with Scaling: {rmse_scaled}')\n",
    "print(f'R-squared with Scaling: {r2_scaled}')\n",
    "print(f'Explained Variance Score with Scaling: {explained_variance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "id": "5J8TozTfB3_X",
    "outputId": "44a1c06e-6b3b-4988-ae9c-4c2478000ffa"
   },
   "outputs": [],
   "source": [
    "# @title Logistic regression\n",
    "\n",
    "# @markdown **Setup:**\n",
    "X = df[features]\n",
    "# Continuous labels:\n",
    "y = \"polyphenols_category\" # @param [\"polyphenols_category\", \"maturity\"]\n",
    "y = df[y]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features (optional but can be beneficial for some algorithms)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test set features\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(f'Confusion Matrix {y.name}')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = sorted(y.unique())\n",
    "tick_marks = range(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, str(cm[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "2WqFUAzKqUbW",
    "outputId": "5167702f-af84-4f88-ac23-9671affd656f"
   },
   "outputs": [],
   "source": [
    "# @title Logistic regression with Custom Confusion Matrix Labels\n",
    "\n",
    "# @markdown **Setup:**\n",
    "X = df[features]\n",
    "# Continuous labels:\n",
    "y = \"maturity\" # @param [\"polyphenols_category\", \"maturity\"]\n",
    "y = df[y]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features (optional but can be beneficial for some algorithms)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set features\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Labels for confusion matrix\n",
    "class_labels = sorted(y.unique()) # Inherit the class labels\n",
    "\n",
    "if len(class_labels) == 2:\n",
    "  # Custom labels for confusion matrix\n",
    "  class_labels = [\"Negative\", \"Positive\"] # custom class labels\n",
    "\n",
    "# Visualize confusion matrix with custom labels\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(f'Confusion Matrix: {y.name}')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xticks(range(len(class_labels)), class_labels)\n",
    "plt.yticks(range(len(class_labels)), class_labels)\n",
    "\n",
    "plt.xlabel(f'Predicted {y.name}')\n",
    "plt.ylabel(f'True {y.name}')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(class_labels)):\n",
    "    for j in range(len(class_labels)):\n",
    "        plt.text(j, i, str(cm[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqXkY4Comso6"
   },
   "source": [
    "### Exercise 2: MLP - Regression and Classification\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In this exercise, the goal is to explore a Multi-Layer Perceptron (MLP) Regressor for continuous variables and an MLP Classifier for categorical variables, while incorporating feature scaling.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "1. **Select the Features:**\n",
    "   - Choose relevant features from the dataset for both MLP regression and classification.\n",
    "\n",
    "2. **Feature Scaling:**\n",
    "   - Utilize feature scaling, such as `StandardScaler()`, to standardize the selected features. This step ensures consistent scaling for both MLP regression and classification.\n",
    "\n",
    "3. **MLP Regressor:**\n",
    "   - Implement a Multi-Layer Perceptron Regressor for predicting continuous target variables.\n",
    "   - Split the standardized dataset into training and testing sets using `train_test_split`.\n",
    "   - Train the MLP Regressor on the training set.\n",
    "   - Make predictions on the test set and evaluate the model's performance using appropriate regression metrics.\n",
    "\n",
    "4. **MLP Classifier:**\n",
    "   - Select a categorical target variable for MLP classification.\n",
    "   - Convert categorical labels into numerical format if needed.\n",
    "   - Split the standardized dataset into training and testing sets.\n",
    "   - Train the MLP Classifier on the training set.\n",
    "   - Make predictions on the test set and evaluate the model's classification performance using appropriate metrics (e.g., accuracy, precision, recall, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuGWarOhuvtF"
   },
   "outputs": [],
   "source": [
    "features = ['volume_ml', 'mass_g', 'length', 'width',\n",
    "       'location_ElJahliye', 'location_Hasbaya', 'location_Rachiine',\n",
    "       'day_time_diff', 'n_days','humidity', 'solar_radiation',\n",
    "       'air_temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "q0XGjDt9gE_i",
    "outputId": "18e3f69e-3bcc-4d81-e51d-93bcd69a8bc3"
   },
   "outputs": [],
   "source": [
    "# @title Multi-Layer Perceptron Regressor\n",
    "# Assuming 'df' is your DataFrame containing the data\n",
    "# and 'polyphenols_content_mg' is the target variable\n",
    "\n",
    "# @markdown **Setup:**\n",
    "X = df[features]\n",
    "# Continuous labels:\n",
    "y = \"polyphenols_content_mg\" # @param [\"polyphenols_content_mg\", \"polyphenols_concentration_mggae/ml\", \"degree_brix\", \"ta_av\", \"mi\"]\n",
    "y = df[y]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the MLP model with scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# You can adjust the parameters of MLPRegressor as needed\n",
    "model = MLPRegressor(hidden_layer_sizes=(500, 1000), max_iter=200, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics on the scaled predictions\n",
    "mse_scaled = mean_squared_error(y_test, y_pred_scaled)\n",
    "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
    "mae_scaled = mean_absolute_error(y_test, y_pred_scaled)\n",
    "rmse_scaled = np.sqrt(mse_scaled)\n",
    "explained_variance = explained_variance_score(y_test, y_pred_scaled)\n",
    "msle_scaled = mean_squared_log_error(y_test, y_pred_scaled)\n",
    "\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(y_test, y_pred_scaled)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], lw=2, color='red')  # Identity line\n",
    "plt.xlabel('Actual polyphenols content (mg)')\n",
    "plt.ylabel('Predicted polyphenols content (mg) - Scaled')\n",
    "plt.title('MLP Regression with Scaling - Actual vs. Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Report the results with scaling\n",
    "print(f'Mean Squared Error with Scaling: {mse_scaled}')\n",
    "print(f'Mean Absolute Error with Scaling: {mae_scaled}')\n",
    "print(f'Root Mean Squared Error with Scaling: {rmse_scaled}')\n",
    "print(f'R-squared with Scaling: {r2_scaled}')\n",
    "print(f'Explained Variance Score with Scaling: {explained_variance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "StvZJFgUhF1V",
    "outputId": "34cb1bc3-b1e0-4ccf-f35f-f7bb2ce7cf4a"
   },
   "outputs": [],
   "source": [
    "# @title Multi-Layer Perceptron Classifier (Categorical variables)\n",
    "# @markdown **Setup:**\n",
    "X = df[features]\n",
    "# Continuous labels:\n",
    "y = \"polyphenols_category\" # @param [\"polyphenols_category\", \"maturity\"]\n",
    "y = df[y]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features (optional but can be beneficial for some algorithms)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the MLP model on original features\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set with original features\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(f'Confusion Matrix {y.name}')\n",
    "plt.colorbar()\n",
    "\n",
    "# Labels for confusion matrix\n",
    "# classes = sorted(y.unique())\n",
    "\n",
    "# Custom labels for confusion matrix\n",
    "classes = [\"Negative\", \"Positive\"] # custom class labels\n",
    "\n",
    "tick_marks = range(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "plt.xlabel(f'Predicted {y.name}')\n",
    "plt.ylabel(f'True {y.name}')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, str(cm[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm-GrSIX-3kt"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W97_uXwNs87O"
   },
   "source": [
    "### Affordable AI: Image Classification (NEW)\n",
    "\n",
    "In real-world scenarios, it's imperative to choose models that balance performance with efficiency, especially when dealing with mobile and edge devices. Lightweight backbones such as MobileNet and the recent MobileViT from Apple are more suitable options when training time and inference time are sensitive parameters.\n",
    "\n",
    "In this exercise, we will delve into the world of affordable AI by utilizing lightweight, efficient models designed for mobile and edge devices. Our focus will be on MobileViT, a hybrid model that combines the strengths of Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). This model is particularly suitable for mobile vision tasks due to its low latency and high performance.\n",
    "\n",
    "You will fine-tune a pre-trained MobileViT model on the Pomegranate dataset. Find the curated image dataset and corresponding tabular data of the pomegranate below:\n",
    "\n",
    "- [CSV File](https://drive.google.com/file/d/1LcTAAA4HZjbiiAabU8pyHIKE9qr1LjWn/view?usp=sharing)\n",
    "- [Data](https://drive.google.com/file/d/1-QRj_YThPDzvUhxVB4Aew647rdl3AGeq/view)\n",
    "\n",
    "\n",
    "Use the following command to unzip the file:\n",
    "```\n",
    "!unzip \"side1.zip\" -q\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpehtg8bs9Zb"
   },
   "outputs": [],
   "source": [
    "!unzip \"side1.zip\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMI-j5KN5gff",
    "outputId": "917c0c9a-762b-4d4a-9ebd-d2491c4bac05"
   },
   "outputs": [],
   "source": [
    "# # Load the dataset\n",
    "df = pd.read_csv('./updated_outlier_pomegranate_complete_cleaned.csv')  # Replace '_.csv' with the actual file path\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNnRQV7B1MKL"
   },
   "source": [
    "#### Install Required Libraries\n",
    "Ensure you have the timm library installed, which provides access to a variety of pre-trained models, including MobileViT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOieFnMx1HGH"
   },
   "outputs": [],
   "source": [
    "!pip install timm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "3Ppzlo-g1ZGW"
   },
   "outputs": [],
   "source": [
    "#@title import required libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from timm.optim import AdamP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Szc3_k6m1iZQ"
   },
   "source": [
    "#### Load and preprocess the image dataset, and select features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X72aeYGQ1zMt"
   },
   "outputs": [],
   "source": [
    "# Combine the encoded metadata with continuous features\n",
    "meta_features = ['no.', 'mass_g', 'volume_ml', 'length', 'width', 'location_ElJahliye', 'location_Hasbaya', 'location_Rachiine',\n",
    "                 'day_time_diff', 'n_days', 'humidity', 'solar_radiation', 'air_temperature']\n",
    "metadata_features = df[meta_features]\n",
    "\n",
    "# Scale numerical metadata features\n",
    "numerical_features = ['mass_g', 'volume_ml', 'length', 'width', 'day_time_diff', 'n_days', 'humidity', 'solar_radiation', 'air_temperature']\n",
    "scaler = StandardScaler()\n",
    "df_numerical = df[meta_features].copy()\n",
    "metadata_features.loc[:, numerical_features] = scaler.fit_transform(metadata_features[numerical_features])\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['polyphenols_category'] = label_encoder.fit_transform(df['polyphenols_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3w-B9rB5kR7"
   },
   "source": [
    "Define `CustomDataset` and `Dataloaders` for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEehnCZK17ng"
   },
   "outputs": [],
   "source": [
    "# Update the CustomDataset to include metadata\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, metadata, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, f\"{int(self.df.iloc[idx, 0])}.jpg\")\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        target = torch.tensor(int(self.df['polyphenols_category'].iloc[idx]))\n",
    "\n",
    "        # Extract metadata for the corresponding sample\n",
    "        metadata_sample = self.metadata.iloc[idx, :].values.astype('float32')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, metadata_sample, target\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define transformations for data augmentation with MobileViT normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create custom datasets and dataloaders\n",
    "image_dir = 'Side 1'  # Update with your actual image directory path\n",
    "train_dataset = CustomDataset(df=train_data, image_dir=image_dir, metadata=metadata_features.loc[train_data.index], transform=transform)\n",
    "val_dataset = CustomDataset(df=val_data, image_dir=image_dir, metadata=metadata_features.loc[val_data.index], transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ2AWzKQ24Fi"
   },
   "source": [
    "#### MobileViT\n",
    "\n",
    "**Why MobileViT?**\n",
    "\n",
    "![img](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IiHPF1KDc5Qd57zyFzwIRw.png)\n",
    "\n",
    "*Source: https://arxiv.org/pdf/2110.02178v2*\n",
    "\n",
    "MobileViT stands out by merging the spatial inductive biases of CNNs with the global representation capabilities of ViTs. This hybrid approach allows MobileViT to achieve remarkable performance with fewer parameters, making it ideal for resource-constrained environments. For instance, MobileViT achieves a top-1 accuracy of 78.4% on the ImageNet-1k dataset with only about 6 million parameters, outperforming both MobileNetv3 (CNN-based) and DeIT (ViT-based) models.\n",
    "\n",
    "### Utilizing Features as Metadata Input for MobileViT\n",
    "\n",
    "Incorporating metadata features into the MobileViT model can significantly enhance its performance and adaptability in image classification tasks. Metadata, which includes additional information such as image context, capture conditions, or even external sensor data, can provide valuable context that the raw image data alone may not capture.\n",
    "\n",
    "#### Benefits of Using Metadata with MobileViT\n",
    "\n",
    "1. **Enhanced Contextual Understanding**:\n",
    "   Metadata can provide context that helps the model better understand the image. For instance, knowing the lighting conditions or the type of device used to capture the image can help the model adjust its processing accordingly.\n",
    "\n",
    "2. **Improved Accuracy**:\n",
    "   By integrating metadata, the model can make more informed predictions. For example, in medical imaging, patient information can be crucial for accurate diagnosis. Similarly, in environmental monitoring, sensor data like temperature and humidity can improve the interpretation of visual data.\n",
    "\n",
    "3. **Reduced Ambiguity**:\n",
    "   Metadata can help reduce ambiguities in image data. For example, two images that look similar might be differentiated by their metadata, such as geographic location or timestamp.\n",
    "\n",
    "4. **Efficient Resource Utilization**:\n",
    "   Leveraging metadata allows the model to allocate resources more efficiently. For instance, if the metadata indicates a high likelihood of a particular class, the model can focus more computational power on verifying that class.\n",
    "\n",
    "#### How to Integrate Metadata into MobileViT\n",
    "\n",
    "To integrate metadata with MobileViT, the metadata can be encoded into a format compatible with the model, such as numerical vectors. These vectors can then be concatenated with the feature maps extracted from the image data before being passed through the classification layers. This approach ensures that the model considers both the visual features and the contextual metadata during the inference process.\n",
    "\n",
    "Incorporating metadata in this manner can make the model achieve a more robust and context-aware image classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9m2-D4kiL5W2",
    "outputId": "e0cb139c-76c1-4983-ec4d-098f93e78e84"
   },
   "outputs": [],
   "source": [
    "# Define the MobileViT model with metadata for classification\n",
    "class MobileViTClassificationWithMetadata(nn.Module):\n",
    "    def __init__(self, num_metadata_features, num_classes, freeze_backbone=True):\n",
    "        super(MobileViTClassificationWithMetadata, self).__init__()\n",
    "        mobilevit = timm.create_model('mobilevit_s.cvnets_in1k', pretrained=True)\n",
    "\n",
    "        # Freeze the backbone layers\n",
    "        if freeze_backbone:\n",
    "            for param in mobilevit.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*list(mobilevit.children())[:-1])  # Remove the last fully connected layer\n",
    "        self.meta_model = nn.Sequential(\n",
    "            nn.Linear(num_metadata_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1000),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.head = nn.Linear(640 + 1000, num_classes)  # Adjust the input size to match the concatenated feature dimensions\n",
    "\n",
    "    def forward(self, x, meta):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)  # Ensure the feature map is 1x1\n",
    "        x = torch.flatten(x, 1)  # Flatten the feature map\n",
    "\n",
    "        meta = self.meta_model(meta)\n",
    "\n",
    "        z = torch.cat([x, meta], 1)\n",
    "\n",
    "        # pass to head\n",
    "        return self.head(z)\n",
    "\n",
    "# In case you want to try another light-weight CNN such as MobileNetV2\n",
    "class MobileNetV2ClassificationWithMetadata(nn.Module):\n",
    "    def __init__(self, num_metadata_features, num_classes, freeze_backbone=False):\n",
    "        super(MobileNetV2ClassificationWithMetadata, self).__init__()\n",
    "        mobilenetv2 = models.mobilenet_v2(pretrained=True)\n",
    "        # Freeze the backbone layers\n",
    "        if freeze_backbone:\n",
    "            for param in mobilenetv2.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.features = mobilenetv2.features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.features = nn.Sequential(*list(mobilenetv2.children())[:-1])  # Remove the last fully connected layer\n",
    "        self.meta_model = nn.Sequential(\n",
    "            nn.Linear(num_metadata_features, 512),\n",
    "            nn.Linear(512,1000),\n",
    "        )\n",
    "        self.head = nn.Linear(1280 + 1000, num_classes)  # Adjust the input size to match the concatenated feature dimensions\n",
    "\n",
    "    # Inside the forward method of your model\n",
    "    def forward(self, x, meta):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        meta = self.meta_model(meta)\n",
    "\n",
    "        z = torch.cat([x, meta], 1)\n",
    "\n",
    "        # pass to backbone\n",
    "        return self.head(z)\n",
    "\n",
    "# Define the MobileViT model with metadata for classification\n",
    "class MobileViTClassificationWithMetadata(nn.Module):\n",
    "    def __init__(self, num_metadata_features, num_classes, freeze_backbone=True):\n",
    "        super(MobileViTClassificationWithMetadata, self).__init__()\n",
    "        mobilevit = timm.create_model('mobilevit_s.cvnets_in1k', pretrained=True)\n",
    "\n",
    "        # Freeze the backbone layers\n",
    "        if freeze_backbone:\n",
    "            for param in mobilevit.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*list(mobilevit.children())[:-1])  # Remove the last fully connected layer\n",
    "        self.meta_model = nn.Sequential(\n",
    "            nn.Linear(num_metadata_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1000),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.head = nn.Linear(640 + 1000, num_classes)  # Adjust the input size to match the concatenated feature dimensions\n",
    "\n",
    "    def forward(self, x, meta):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)  # Ensure the feature map is 1x1\n",
    "        x = torch.flatten(x, 1)  # Flatten the feature map\n",
    "\n",
    "        meta = self.meta_model(meta)\n",
    "\n",
    "        z = torch.cat([x, meta], 1)\n",
    "\n",
    "        # pass to head\n",
    "        return self.head(z)\n",
    "\n",
    "# Instantiate the model for three classes (low, moderate, high)\n",
    "num_metadata_features = metadata_features.shape[1]\n",
    "num_classes = 3\n",
    "model = MobileViTClassificationWithMetadata(num_metadata_features, num_classes)\n",
    "num_epochs = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamP(model.parameters(), lr=0.0001, betas=(0.9, 0.999), weight_decay=1e-3)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.00001)\n",
    "\n",
    "# Training loop\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, metadata, targets in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        inputs, metadata, targets = inputs.to(device), metadata.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, metadata)\n",
    "\n",
    "        # Debugging output\n",
    "        if outputs is None:\n",
    "            print(f'Outputs are None for batch {inputs.size(0)}')\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, metadata, targets in tqdm(val_loader, desc=f'Validation'):\n",
    "            inputs, metadata, targets = inputs.to(device), metadata.to(device), targets.to(device)\n",
    "            outputs = model(inputs, metadata)\n",
    "\n",
    "            # Debugging output\n",
    "            if outputs is None:\n",
    "                print(f'Outputs are None for validation batch {inputs.size(0)}')\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), f'{y_}_classification_model_with_metadata_mobilevit.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eCN56NgyAbV"
   },
   "source": [
    "#### Continuous variables\n",
    "\n",
    "We could also expand it to a regression problem, similar to our MLP regressor, and parameterize the features as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mske3s2QyC1z",
    "outputId": "4356a805-111d-42e0-d430-3cf6026155f2"
   },
   "outputs": [],
   "source": [
    "# @markdown **Features:**\n",
    "# @markdown **Features:**\n",
    "root_directory=\"./\"\n",
    "volume_ml = False  # @param {type:\"boolean\"}\n",
    "mass_g = True  # @param {type:\"boolean\"}\n",
    "length = True  # @param {type:\"boolean\"}\n",
    "width = True  # @param {type:\"boolean\"}\n",
    "location_ElJahliye = True  # @param {type:\"boolean\"}\n",
    "location_Hasbaya = True  # @param {type:\"boolean\"}\n",
    "location_Rachiine = True  # @param {type:\"boolean\"}\n",
    "days_since_harvesting = False  # @param {type:\"boolean\"}\n",
    "harvesting_mapping = False # @param {type:\"boolean\"}\n",
    "humidity = True  # @param {type:\"boolean\"}\n",
    "solar_radiation = True  # @param {type:\"boolean\"}\n",
    "air_temperature = True  # @param {type:\"boolean\"}\n",
    "precipitation = False  # @param {type:\"boolean\"}\n",
    "dilution = False  # @param {type:\"boolean\"}\n",
    "\n",
    "features = []\n",
    "\n",
    "# Dictionary containing feature names and their corresponding boolean values\n",
    "boolean_values = {\n",
    "    'volume_ml': volume_ml,\n",
    "    'mass_g': mass_g,\n",
    "    'length': length,\n",
    "    'width': width,\n",
    "    'location_ElJahliye': location_ElJahliye,\n",
    "    'location_Hasbaya': location_Hasbaya,\n",
    "    'location_Rachiine': location_Rachiine,\n",
    "    'normalized_days_since_harvesting': days_since_harvesting,\n",
    "    'harvesting_mapping': harvesting_mapping,\n",
    "    'humidity': humidity,\n",
    "    'solar_radiation': solar_radiation,\n",
    "    'air_temperature': air_temperature,\n",
    "    'precipitation': precipitation,\n",
    "    'dilution': dilution,\n",
    "}\n",
    "\n",
    "# Loop through the dictionary and append feature names to the features list if the boolean value is True\n",
    "for feature, value in boolean_values.items():\n",
    "    if value:\n",
    "        features.append(feature)\n",
    "\n",
    "print(\"Features used:\\n\",features)\n",
    "\n",
    "# @markdown **Setup:**\n",
    "metadata_features = df[features]\n",
    "# # Continuous labels:\n",
    "y_ = \"polyphenols_content_mg\" # @param [\"polyphenols_content_mg\", \"polyphenols_concentration_mggae/ml\", \"degree_brix\", \"ta_av\", \"mi\", \"color_intensity\"]\n",
    "y = df[y_]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "import timm.optim\n",
    "import timm.scheduler.cosine_lr\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# Extract numerical features dynamically\n",
    "numerical_features = metadata_features.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "# Scale numerical metadata features\n",
    "scaler = StandardScaler()\n",
    "df_numerical = metadata_features[numerical_features].copy()\n",
    "df_numerical[numerical_features] = scaler.fit_transform(df_numerical[numerical_features])\n",
    "\n",
    "metadata_features[numerical_features]= df_numerical[numerical_features]\n",
    "\n",
    "# Update the CustomDataset to include metadata\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, metadata, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, f\"{int(self.df.iloc[idx, 0])}.jpg\")\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        target = torch.tensor(float(self.df[['no.',y_]].iloc[idx, 1]))\n",
    "\n",
    "        # Extract metadata for the corresponding sample\n",
    "        metadata_sample = self.metadata.iloc[idx, :].values.astype('float32')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, metadata_sample, target\n",
    "\n",
    "\n",
    "# @markdown Train-test split:\n",
    "split = 0.2 # @param {type:\"number\"}\n",
    "\n",
    "# Initialize Stratified Shuffle Split based on location\n",
    "stratify= \"location\" # @param [\"location\", \"None\"]\n",
    "if stratify==\"None\":\n",
    "  # Split the data into training and validation sets\n",
    "  train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "else:\n",
    "  strat_split = StratifiedShuffleSplit(n_splits=1, test_size=split, random_state=42)\n",
    "  for train_index, test_index in strat_split.split(df, df[stratify]):\n",
    "      train_data, val_data = df.iloc[train_index], df.iloc[test_index]\n",
    "      # y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "# Define transformations for data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create custom datasets and dataloaders\n",
    "image_dir = \"./Side 1\"  # Update with your actual image directory path\n",
    "train_dataset = CustomDataset(df=train_data, image_dir=image_dir, metadata=metadata_features.loc[train_data.index], transform=transform)\n",
    "val_dataset = CustomDataset(df=val_data, image_dir=image_dir, metadata=metadata_features.loc[val_data.index], transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# Define the MobileViT model with metadata for classification\n",
    "class MobileViTClassificationWithMetadata(nn.Module):\n",
    "    def __init__(self, num_metadata_features, freeze_backbone=True):\n",
    "        super(MobileViTClassificationWithMetadata, self).__init__()\n",
    "        mobilevit = timm.create_model('mobilevit_s.cvnets_in1k', pretrained=True)\n",
    "\n",
    "        # Freeze the backbone layers\n",
    "        if freeze_backbone:\n",
    "            for param in mobilevit.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*list(mobilevit.children())[:-1])  # Remove the last fully connected layer\n",
    "        self.meta_model = nn.Sequential(\n",
    "            nn.Linear(num_metadata_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1000),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.head = nn.Linear(640 + 1000, 1)  # Adjust the input size to match the concatenated feature dimensions\n",
    "\n",
    "    def forward(self, x, meta):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)  # Ensure the feature map is 1x1\n",
    "        x = torch.flatten(x, 1)  # Flatten the feature map\n",
    "\n",
    "        meta = self.meta_model(meta)\n",
    "\n",
    "        z = torch.cat([x, meta], 1)\n",
    "\n",
    "        # pass to head\n",
    "        return self.head(z)\n",
    "\n",
    "# Instantiate the model\n",
    "num_metadata_features = metadata_features.shape[1]\n",
    "model = MobileViTClassificationWithMetadata(num_metadata_features)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = timm.optim.AdamP(model.parameters(), lr=0.001, weight_decay= 0.00005)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "best_val_loss = float('inf')  # Initialize with a large value\n",
    "best_val_r2_score = float('-inf')  # Initialize with negative infinity\n",
    "best_model_state = None\n",
    "\n",
    "# Cosine annealing scheduler\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "# Cosine annealing scheduler\n",
    "# scheduler = timm.scheduler.cosine_lr(optimizer, t_initial=num_epochs, warmup_t=5, cycle_decay= 0.9, cycle_limit= 2, lr_min= 0.00001)\n",
    "\n",
    "\n",
    "# Lists to store training and validation loss, and scores\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "\n",
    "# Lists to store training and validation loss, R2 score, MSE, MAE, RMSE, and explained variance score\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_r2_scores = []\n",
    "val_r2_scores = []\n",
    "train_mse = []\n",
    "val_mse = []\n",
    "train_mae = []\n",
    "val_mae = []\n",
    "train_rmse = []\n",
    "val_rmse = []\n",
    "train_ev_scores = []\n",
    "val_ev_scores = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_loss_sum = 0.0\n",
    "    train_predictions = []\n",
    "    train_targets = []\n",
    "    for inputs, metadata, targets in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        inputs, metadata, targets = inputs.to(device), metadata.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, metadata)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step(epoch)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_loss_sum += np.sum((outputs.squeeze().detach().cpu().numpy() - targets.detach().cpu().numpy()) ** 2)\n",
    "\n",
    "        # Collect predictions and targets for computing R2 score, MSE, MAE, and explained variance score\n",
    "        train_predictions.extend(outputs.squeeze().detach().cpu().numpy())\n",
    "        train_targets.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_mse.append(train_loss_sum / len(train_loader.dataset))\n",
    "    train_r2_scores.append(r2_score(train_targets, train_predictions))\n",
    "    train_mae.append(mean_absolute_error(train_targets, train_predictions))\n",
    "    train_rmse.append(np.sqrt(train_mse[-1]))\n",
    "    train_ev_scores.append(explained_variance_score(train_targets, train_predictions))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_loss_sum = 0.0\n",
    "    val_predictions = []\n",
    "    val_targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, metadata, targets in tqdm(val_loader, desc=f'Validation'):\n",
    "            inputs, metadata, targets = inputs.to(device), metadata.to(device), targets.to(device)\n",
    "            outputs = model(inputs, metadata)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            val_loss += loss.item()\n",
    "            val_loss_sum += np.sum((outputs.squeeze().detach().cpu().numpy() - targets.detach().cpu().numpy()) ** 2)\n",
    "\n",
    "            # Collect predictions and targets for computing R2 score, MSE, MAE, and explained variance score\n",
    "            val_predictions.extend(outputs.squeeze().detach().cpu().numpy())\n",
    "            val_targets.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_mse.append(val_loss_sum / len(val_loader.dataset))\n",
    "    val_r2_score = r2_score(val_targets, val_predictions) # R2 metric\n",
    "    val_r2_scores.append(val_r2_score)\n",
    "    val_mae.append(mean_absolute_error(val_targets, val_predictions))\n",
    "    val_rmse.append(np.sqrt(val_mse[-1]))\n",
    "    val_ev_scores.append(explained_variance_score(val_targets, val_predictions))\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Training MSE: {train_mse[-1]:.4f}, Validation MSE: {val_mse[-1]:.4f}, Training R2 Score: {train_r2_scores[-1]:.4f}, Validation R2 Score: {val_r2_scores[-1]:.4f}, Training MAE: {train_mae[-1]:.4f}, Validation MAE: {val_mae[-1]:.4f}, Training RMSE: {train_rmse[-1]:.4f}, Validation RMSE: {val_rmse[-1]:.4f}, Training Explained Variance Score: {train_ev_scores[-1]:.4f}, Validation Explained Variance Score: {val_ev_scores[-1]:.4f}')\n",
    "    # Update best validation loss and save the model if it's the best so far\n",
    "    # Save the model if validation R2 score improves\n",
    "    if val_r2_score > best_val_r2_score:\n",
    "        best_val_r2_score = val_r2_score\n",
    "        best_model_state = model.state_dict()\n",
    "        # Save the best model state\n",
    "        torch.save(best_model_state, f'{root_directory}/best_model.pth')\n",
    "\n",
    "# Plotting\n",
    "# Plot training and validation loss curves\n",
    "fig_loss = plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig_loss.savefig('training_validation_loss.png')\n",
    "\n",
    "# Plot training and validation R2 scores\n",
    "fig_r2 = plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_r2_scores, label='Training R2 Score')\n",
    "plt.plot(val_r2_scores, label='Validation R2 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title('Training and Validation R2 Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig_r2.savefig('training_validation_r2.png')\n",
    "\n",
    "# Plot training and validation MSE\n",
    "fig_mse = plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_mse, label='Training MSE')\n",
    "plt.plot(val_mse, label='Validation MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig_mse.savefig('training_validation_mse.png')\n",
    "\n",
    "# Plot training and validation MAE\n",
    "fig_mae = plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_mae, label='Training MAE')\n",
    "plt.plot(val_mae, label='Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig_mae.savefig('training_validation_mae.png')\n",
    "\n",
    "# Plot training and validation RMSE\n",
    "fig_rmse = plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_rmse, label='Training RMSE')\n",
    "plt.plot(val_rmse, label='Validation RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Root Mean Squared Error')\n",
    "plt.title('Training and Validation RMSE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig_rmse.savefig('training_validation_rmse.png')\n",
    "\n",
    "# Plot training and validation explained variance score\n",
    "fig_ev = plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_ev_scores, label='Training Explained Variance Score')\n",
    "plt.plot(val_ev_scores, label='Validation Explained Variance Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Explained Variance Score')\n",
    "plt.title('Training and Validation Explained Variance Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig_ev.savefig('training_validation_ev.png')\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Create a dictionary to store values\n",
    "metrics_dict = {\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_r2_scores': train_r2_scores,\n",
    "    'val_r2_scores': val_r2_scores,\n",
    "    'train_mse': train_mse,\n",
    "    'val_mse': val_mse,\n",
    "    'train_mae': train_mae,\n",
    "    'val_mae': val_mae,\n",
    "    'train_rmse': train_rmse,\n",
    "    'val_rmse': val_rmse,\n",
    "    'train_ev_scores': train_ev_scores,\n",
    "    'val_ev_scores': val_ev_scores\n",
    "}\n",
    "\n",
    "# # Save the dictionary to a file using pickle\n",
    "# with open('metrics_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(metrics_dict, f)\n",
    "\n",
    "# Save the dictionary to a file using pickle\n",
    "with open(f'{root_directory}/metrics_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fjkaj9bpC4RD"
   },
   "source": [
    "#### Bonus: Pomegranate Fruit Dataset\n",
    "\n",
    "With the following code snipets you'll be able to train a similar dataset on pomogranate frout,. However in this case you can use it as a pretrained model and then fine-tune it on our interest data.\n",
    "\n",
    "This procedure brings closer the distribution of the pretrained weights for the pomegranate context and may improve performance in some scenarios.\n",
    "\n",
    "[The Pomegranate Fruit dataset](https://www.kaggle.com/datasets/kumararun37/pomegranate-fruit-dataset), you may also download it here [here](https://drive.google.com/file/d/1tmwglFG8SZ8U7iuwBsB68YmLwQB9pfwq/view).\n",
    "\n",
    "Simlarly we will unzip the contents with the command\n",
    "\n",
    "```\n",
    "!unzip \"pomegranate_fruit.zip\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7IbHzWGFB2B"
   },
   "outputs": [],
   "source": [
    "!unzip \"pomegranate_fruit.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFATv2Nc89by"
   },
   "source": [
    "The task here is simple and we'll summarize it even more:\n",
    "\n",
    "There are three qualities for the pomegranate:\n",
    "\n",
    "*   `G1` Superior quality look with fully ripe Attractive red or rose pink 300-400 85.39-106.12 Smooth, slight superficial defects not affecting the look and quality 10%.\n",
    "*   `G2` Good look with fully ripe Attractive red or rose pink. Improper coloring may be present 200-300 74.72-89.23\n",
    "Slight defects like scar, scratch, scrape, blemish etc. may be allowed, not affecting the look and quality 10%.\n",
    "*   `G3` Good look with fully ripe Attractive red or rose pink. Improper coloring may be present 100-200 64.85-78.15 Slight defects like scar, scratch, scrape, blemish etc. may be allowed, not affecting the look and quality 10%.\n",
    "\n",
    "We'll train a classifier on this task and then fine-tune the model in our pomegranate dataset. Can you spot an improvement? Feel free to play with the hyperparameters such as: `learning rate`, `batch_size`, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "DIzBVx_P87a1"
   },
   "outputs": [],
   "source": [
    "#@title Show images\n",
    "\n",
    "# Define the paths\n",
    "base_path = '/content/to upload'\n",
    "folders = ['G1_Q1', 'G1_Q2', 'G1_Q3', 'G1_Q4', 'G2_Q1', 'G2_Q2', 'G2_Q3', 'G2_Q4', 'G3_Q1', 'G3_Q2', 'G3_Q3', 'G3_Q4']\n",
    "\n",
    "# Prepare a list to hold image paths and labels\n",
    "data = []\n",
    "\n",
    "# Iterate through each folder and gather the images and their labels\n",
    "for folder in folders:\n",
    "    quality = folder.split('_')[0]  # Extract G1, G2, or G3\n",
    "    quality_label = int(quality[1]) - 1  # Convert G1, G2, G3 to 0, 1, 2\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            data.append((file_path, quality_label))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['image_path', 'label'])\n",
    "\n",
    "# Update the CustomDataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = torch.tensor(self.df.iloc[idx]['label'])\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# Stratified split into training and validation sets\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = next(skf.split(df, df['label']))\n",
    "\n",
    "train_data = df.iloc[train_idx].reset_index(drop=True)\n",
    "val_data = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "# Define transformations for data augmentation with MobileViT normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation(20),\n",
    "    # transforms.RandomCrop(224, padding=4),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create custom datasets and dataloaders\n",
    "train_dataset = CustomDataset(df=train_data, transform=transform)\n",
    "val_dataset = CustomDataset(df=val_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Function to plot some samples from the DataLoader\n",
    "def plot_samples(dataloader, num_samples=8):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images = images[:num_samples]\n",
    "    labels = labels[:num_samples]\n",
    "\n",
    "    # Unnormalize the images for visualization\n",
    "    inv_normalize = transforms.Normalize(\n",
    "        mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225],\n",
    "        std=[1 / 0.229, 1 / 0.224, 1 / 0.225]\n",
    "    )\n",
    "    unnormalized_images = [inv_normalize(img).permute(1, 2, 0).numpy() for img in images]\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for i in range(num_samples):\n",
    "        ax = plt.subplot(2, num_samples // 2, i + 1)\n",
    "        plt.imshow(unnormalized_images[i])\n",
    "        plt.title(f'Label: {labels[i].item()}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot samples from the train_loader\n",
    "plot_samples(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "o8YWFhmbseJi"
   },
   "outputs": [],
   "source": [
    "#@title Train model\n",
    "# Define the paths\n",
    "base_path = '/content/to upload'\n",
    "folders = ['G1_Q1', 'G1_Q2', 'G1_Q3', 'G1_Q4', 'G2_Q1', 'G2_Q2', 'G2_Q3', 'G2_Q4', 'G3_Q1', 'G3_Q2', 'G3_Q3', 'G3_Q4']\n",
    "\n",
    "# Prepare a list to hold image paths and labels\n",
    "data = []\n",
    "\n",
    "# Iterate through each folder and gather the images and their labels\n",
    "for folder in folders:\n",
    "    quality = folder.split('_')[0]  # Extract G1, G2, or G3\n",
    "    quality_label = int(quality[1]) - 1  # Convert G1, G2, G3 to 0, 1, 2\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            data.append((file_path, quality_label))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['image_path', 'label'])\n",
    "\n",
    "# Update the CustomDataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = torch.tensor(self.df.iloc[idx]['label'])\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# Stratified split into training and validation sets\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = next(skf.split(df, df['label']))\n",
    "\n",
    "train_data = df.iloc[train_idx].reset_index(drop=True)\n",
    "val_data = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "# Define transformations for data augmentation with MobileViT normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create custom datasets and dataloaders\n",
    "train_dataset = CustomDataset(df=train_data, transform=transform)\n",
    "val_dataset = CustomDataset(df=val_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the MobileViT model for classification\n",
    "class MobileViTClassification(nn.Module):\n",
    "    def __init__(self, num_classes, freeze_backbone=True):\n",
    "        super(MobileViTClassification, self).__init__()\n",
    "        mobilevit = timm.create_model('mobilevit_s.cvnets_in1k', pretrained=True)\n",
    "\n",
    "        # Freeze the backbone layers\n",
    "        if freeze_backbone:\n",
    "            for param in mobilevit.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*list(mobilevit.children())[:-1])  # Remove the last fully connected layer\n",
    "        self.head = nn.Linear(mobilevit.num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)  # Ensure the feature map is 1x1\n",
    "        x = torch.flatten(x, 1)  # Flatten the feature map\n",
    "        return self.head(x)\n",
    "\n",
    "# Instantiate the model for three classes (G1, G2, G3)\n",
    "num_classes = 3\n",
    "model = MobileViTClassification(num_classes)\n",
    "num_epochs = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamP(model.parameters(), lr=0.0001, betas=(0.9, 0.999), weight_decay=1e-3)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.00001)\n",
    "\n",
    "# Training loop\n",
    "model.to(device)\n",
    "\n",
    "# Lists to store training and validation loss and accuracy\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for inputs, targets in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        _, predicted_train = outputs.max(1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += predicted_train.eq(targets).sum().item()\n",
    "\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=f'Validation'):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted_val = outputs.max(1)\n",
    "            total_val += targets.size(0)\n",
    "            correct_val += predicted_val.eq(targets).sum().item()\n",
    "\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}, Training Accuracy: {train_accuracies[-1]:.4f}, Validation Accuracy: {val_accuracies[-1]:.4f}')\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "# Plot the loss and accuracy\n",
    "def plot_loss_and_accuracy(epochs_range, train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plotting loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, train_losses, label='Train')\n",
    "    plt.plot(epochs_range, val_losses, label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, train_accuracies, label='Train')\n",
    "    plt.plot(epochs_range, val_accuracies, label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "plot_loss_and_accuracy(range(num_epochs), train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'quality_classification_model_mobilevit.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "oZ8pZQ1n6EMk"
   },
   "outputs": [],
   "source": [
    "#@title Load our previous code snipet in a single cell and run the model\n",
    "# Combine the encoded metadata with continuous features\n",
    "meta_features = ['no.', 'mass_g', 'volume_ml', 'length', 'width', 'location_ElJahliye', 'location_Hasbaya', 'location_Rachiine',\n",
    "                 'day_time_diff', 'n_days', 'humidity', 'solar_radiation', 'air_temperature']\n",
    "metadata_features = df[meta_features]\n",
    "\n",
    "# Scale numerical metadata features\n",
    "numerical_features = ['mass_g', 'volume_ml', 'length', 'width', 'day_time_diff', 'n_days', 'humidity', 'solar_radiation', 'air_temperature']\n",
    "scaler = StandardScaler()\n",
    "df_numerical = df[meta_features].copy()\n",
    "metadata_features.loc[:, numerical_features] = scaler.fit_transform(metadata_features[numerical_features])\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['polyphenols_category'] = label_encoder.fit_transform(df['polyphenols_category'])\n",
    "\n",
    "# Update the CustomDataset to include metadata\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, metadata, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, f\"{int(self.df.iloc[idx, 0])}.jpg\")\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        target = torch.tensor(int(self.df['polyphenols_category'].iloc[idx]))\n",
    "\n",
    "        # Extract metadata for the corresponding sample\n",
    "        metadata_sample = self.metadata.iloc[idx, :].values.astype('float32')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, metadata_sample, target\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define transformations for data augmentation with MobileViT normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create custom datasets and dataloaders\n",
    "image_dir = 'Side 1'  # Update with your actual image directory path\n",
    "train_dataset = CustomDataset(df=train_data, image_dir=image_dir, metadata=metadata_features.loc[train_data.index], transform=transform)\n",
    "val_dataset = CustomDataset(df=val_data, image_dir=image_dir, metadata=metadata_features.loc[val_data.index], transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the MobileViT model with metadata for classification\n",
    "class MobileViTClassificationWithMetadata(nn.Module):\n",
    "    def __init__(self, num_metadata_features, num_classes, freeze_backbone=True):\n",
    "        super(MobileViTClassificationWithMetadata, self).__init__()\n",
    "        mobilevit = timm.create_model('mobilevit_s.cvnets_in1k', pretrained=True)\n",
    "\n",
    "        # Load the pre-trained weights from code 1\n",
    "        state_dict = torch.load('quality_classification_model_mobilevit.pth')\n",
    "        mobilevit.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        # Freeze the backbone layers\n",
    "        if freeze_backbone:\n",
    "            for param in mobilevit.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*list(mobilevit.children())[:-1])  # Remove the last fully connected layer\n",
    "        self.meta_model = nn.Sequential(\n",
    "            nn.Linear(num_metadata_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1000),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.head = nn.Linear(mobilevit.num_features + 1000, num_classes)  # Adjust the input size to match the concatenated feature dimensions\n",
    "\n",
    "    def forward(self, x, meta):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)  # Ensure the feature map is 1x1\n",
    "        x = torch.flatten(x, 1)  # Flatten the feature map\n",
    "\n",
    "        meta = self.meta_model(meta)\n",
    "\n",
    "        z = torch.cat([x, meta], 1)\n",
    "\n",
    "        # Pass to head\n",
    "        return self.head(z)\n",
    "\n",
    "# Instantiate the model for three classes (low, moderate, high)\n",
    "num_metadata_features = metadata_features.shape[1]\n",
    "num_classes = 3\n",
    "model = MobileViTClassificationWithMetadata(num_metadata_features, num_classes)\n",
    "num_epochs = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamP(model.parameters(), lr=0.0001, betas=(0.9, 0.999), weight_decay=1e-3)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.00001)\n",
    "\n",
    "# Training loop\n",
    "model.to(device)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for inputs, metadata, targets in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        inputs, metadata, targets = inputs.to(device), metadata.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, metadata)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += predicted.eq(targets).sum().item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(correct_train / total_train)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, metadata, targets in tqdm(val_loader, desc=f'Validation'):\n",
    "            inputs, metadata, targets = inputs.to(device), metadata.to(device), targets.to(device)\n",
    "            outputs = model(inputs, metadata)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += targets.size(0)\n",
    "            correct_val += predicted.eq(targets).sum().item()\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accuracies.append(correct_val / total_val)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}, Training Accuracy: {train_accuracies[-1]:.4f}, Validation Accuracy: {val_accuracies[-1]:.4f}')\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'polyphenols_classification_model_with_metadata_mobilevit.pth')\n",
    "\n",
    "# Plot the loss and accuracy\n",
    "def plot_loss_and_accuracy(epochs_range, train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plotting loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, train_losses, label='Train')\n",
    "    plt.plot(epochs_range, val_losses, label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, train_accuracies, label='Train')\n",
    "    plt.plot(epochs_range, val_accuracies, label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "plot_loss_and_accuracy(range(num_epochs), train_losses, val_losses, train_accuracies, val_accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questionnaire\n",
    "Hope you enjoyed the exercise! \n",
    "Before you leave, please fill in our questionnaire (link via the qr code below).\n",
    "Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/albarqounilab/SAAI-Summer-School/raw/main/questionnaires/AffAI_question_qr.png\" width=\"200\" height=\"100\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUkk9Y8vxvra"
   },
   "source": [
    "`Please remember to treat this notebook and the data confidentially.`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RW2F8fSw0QNC",
    "Fjkaj9bpC4RD"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
